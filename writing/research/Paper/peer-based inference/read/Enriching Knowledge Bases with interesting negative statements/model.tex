\section{Model}
\label{sec:formalization}

%\GW{problem statements and research problems come a little late here, all this should be clear already by now;
%hence rename the section into "Model and Design Space",
%and drop repetitive "problem formalizations";\\
%the entire section does not look and work like a design space discussion, most is about the model, and the alternative designs are just deleted statements and something vague about PCA, plus there is some repetition of related work;\\
%either beef this up with systematic discussion, or change the heading and trim the section}\ha{**}\\

For the remainder we assume that a KB is a set of statements, each being a triple $(s;p;o)$ of subject $s$, property $p$ and object $o$.

%\noindent
%\textbf{Formalization.\ }
%For the remainder we assume that a KB$\doteq (\mathcal{T}, \mathcal{S})$ consists of $\mathcal T$ is a set of %statements, each being a\ triples \term{(s; p; o)} of subject \term{s}, property \term{p} and object \term{o}, while $\mathcal S$ is the schema, or TBox in the terminology of Description Logics (DLs). We refer the reader to \cite{logichandbook,Pan2016, Pan2017} for a more detailed introduction of description logics and knowledge graphs. In this paper, we assume that the KB might have very simple schema axioms, such as domain axioms for properties.  \\
%\GW{unnecessarily wide: we only need SPO statements, can't we define this in one sentence?}\ha{**}\\

Let $K^i$ be an (imaginary) ideal KB that perfectly represents reality, i.e., contains exactly those statements that hold in reality. Under the OWA, (practically) available KBs, $K^a$ contains correct statements, but may be incomplete, so the condition $K^a \subseteq K^i$ holds, but not the converse \cite{razniewski2011completeness}.
We distinguish two forms of negative statements.


\begin{defn}[Negative Statements] \mbox{ }
 % Let $s,o$ be  entities,   and $p$ a property:
\begin{enumerate}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\item A grounded negative statement $\neg (s, p, o)$ is satisfied if $(s, p, o) \notin K^i$.
 %   \item A \textit{grounded negative statement} {\normalfont \term{$\neg$(s; p; o)}} is  satisfied if $K^i \ \cup \ \{ ${\normalfont \term{(s; p; o)}}$\} \models \bot$ and $K^{i} \models s:domain(p)$, % is not in $K^i$.
%    \item A \textit{restricted negative statement} {\normalfont \term{$\neg\exists$(s; p; \_), (\_, p', o')}} is satisfied if there exists no {\normalfont \term{o}} such that {\normalfont \term{(s; p; o) and (o, p', o')}} are in $K^i$.
\item A universally  negative statement $\neg\exists o: (s, p, o)$ is satisfied if there exists no $o$ such that $(s; p; o) \in K^i$.
%    \item A \textit{universally negative statement} {\normalfont \term{$\neg$(s; p; \_)} is satisfied if $K^i \ \cup \ $ \{\term s: $  \exists \term p.\top)\}   \models \bot$, where domain(\term p) is the domain of the property \term p.}%; 
 %   \item  A \textit{scoped universally negative statement} {\normalfont \term{$\neg$(s; p; \_)$_{Sc}$  } is satisfied if $K^i \cup $ \{\term s$: %domain(\term p)
   % Sc \sqcap \forall \term p.\bot\} \not \models \bot$, where $Sc$ is the scope class.%;
\end{enumerate} 
\end{defn}

%\sr{Thanks making this more formal! One question on syntax though, if I instantiate the second definition with (Merkel, child, \_), I obtain that this statement is satisfied, if $K^i \ \cup \ $ \{\term Merkel: $\neg($domain(\term child)$\ \sqcap \ \forall \term child.\bot)\}   \models \bot$, where the second part of the union, I presume, corresponds to something like \{\term Merkel: $\neg(Merkel, Putin, Pope Francis, ...)\}$ - which looks syntactically not quite right - is there perhaps something missing?}

%\GW{here you need examples!!!!!}

%\jeff{Thanks for checking. In the case of (Markel, child, \_), we have \{Markel: $\neg (Person \sqcap \forall child.\bot$)\} union with K$^i$ should be inconsistent. Note that \{Markel: $\neg (Person \sqcap \forall child.\bot$)\} can be transformed into \{Markel: $\neg Person \sqcup \exists child.\top\}$ }

An example of a grounded negative statement is that \textit{``Bruce Willis was not born in the U.S.''}, and is expressed as \term{$\neg$(Bruce Willis; born in; U.S.)}. An example of a universally negative statement is that \textit{``Leonardo DiCaprio has never been married''}, expressed as \term{$\neg\exists o:$(Leonardo DiC\-aprio; spouse; o)}. Both types of negative statements represent standard logical constructs, and could also be expressed in the OWL ontology language. Grounded negative statements could be expressed via negative property statements (e.g., {\small{\texttt{NegativeObjectPropertyAssertion }}{\small\texttt{(:born In :Bruce Willis :U.S.)}}}), while universally negative statements could be expressed via \texttt{ObjectAllValuesFrom} or \texttt{owl:complementOf} \cite{erxleben2014introducing} (e.g., {\small{\texttt{ ClassAssertion (ObjectAl\-lValuesFrom (:spouse owl:Nothing) :Leonardo Dicaprio)}}}). Without further constraints, for these classes of negative statements, checking that there is no conflict with a positive statement is trivial. In the presence of further constraints or entailment regimes, one could resort to (in)cons\-istency checking services \cite{logichandbook,Pan2017,gadwww}.

% SR: Reformulated a bit, note that consistency is not the same as correctness. A statement like ``Simon has no siblings'' is consistent with a KB, until someone asserts a sibling. Whereas correctness is a somewhat higher goal, of not just asking whether one can state something contradiction-free, but whether the statement is also true in reality.


Yet compiling negative statements faces two other challenges.
First, being not in conflict with positive statements is a necessary but not a sufficient condition for correctness of negation, due to the OWA. In particular, $K^i$ is only a virtual construct, so methods to derive correct negative statements have to rely on the limited positive information contained in $K^a$, or utilize external evidence, e.g., from text. Second, the set of correct negative statements is near-infinite, especially for grounded negative statements. Thus, unlike for positive statements, negative statement construction/extraction needs a tight coupling with ranking methods.

\noindent
\textbf{Research Problem 1.\ }
Given an entity $e$, compile a ranked list of useful grounded negative and universally negative statements.


%\noindent
%\textbf{Design Space.\ }
%A first thought is that \textit{deletions from time-variant KBs} are a natural source. For instance, in Wikidata, for subjects of type
%person
%within the year 2018, more than 500K triples have been deleted. Yet on careful inspection we found that most of these concern ontology restructuring, granularity refinements, or blatant typos, thus do not give rise to important negation.\\
%\GW{this is mere repetition of related work}\ha{**}\\


%A second conceivable approach is to leverage the CWA, or its relaxed variant PCA (Partial Completeness Assumption, aka. LCWA for Local CWA) \cite{AMIEP}, to generate negative statements. \newtext{Informally, PCA says if an entity $s$ has some value for a property  $p$, then we can assume that  all of its values for $p$ are in $KB^a$}
%\newtext{
%\begin{defn}[Partial Completeness Assumption] \mbox{ }
% The PCA is the assumption that if
%Given 
%\term{(s; p; o)} $\in K^a$ %for 
%some entities $s,o$ and property $p$, 
%then: %
%the partial completeness assumption states that
%\small
%\begin{equation}
%\label{eqn:pca}
%\forall (s; p; o'): (s; p; o') \in K^i \Longleftrightarrow (s; p; o') \in K^a.
%\end{equation}
%\normalsize
%\end{defn}
%}
%\GW{no OWL here: good; the variables in the universal quantifier do not make sense, since you already said that this is for a given spo $\in$ Ka -- so the universal quantifier should be forall o' only; alternatively you can drop the prefix "if spo $\in$ Ka", but then the entire formula needs to be written differently}\ha{**}\\

%Using just the active domain of Wikidata for grounding, the CWA would give rise to about $6.4\times10^{18}$ negative statements\footnote{80 Million subjects times 1000 properties times 80 Million objects.}. Assuming that Wikidata covers 10\% of all true statements per entity, more than 99.999\% of the negative statements would be correct, but hardly noteworthy. For the PCA, the total would be about $3.2\times10^{16}$ negative statements (assuming an average of 5 populated properties per entity), and almost all of these would be correct.
%But these approaches would miss the true issue: merely enumerating huge sets of negative statements is not insightful even with (trivially) high precision.
%The key challenge rather is to identify useful statements that users find noteworthy.

%Statistical inference methods, ranging from association rule mining such as AMIE and RuDiK~\cite{AMIE,ortona2018rudik} to embedding models such as TransE and HolE~\cite{transE,holE} can predict positive statements and provide ranked lists of role fillers for KB relations. In Section~\ref{sec:inference}, we develop a statistical inference method for negative statements, which generates candidate sets from related entities, and uses a set of popularity and probability heuristics in order to rank these statements. 