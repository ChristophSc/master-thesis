\section{Sampling by Uncertainty} 
\label{sec:sampling_by_uncertainty}

8) Sampling by Uncertainty
- calculate uncertainty of model for all negative triples from negative triple set $Neg$
- Option1: always sample the maximum
- Option2: calculate a probability distribution again and sample the triples with highest uncertainty with highest probability



To sample the negative triple $(h',r,t')^{*}_{ENT}$, we need to calculate the entropy-based uncertainty, which is defined as: 
$$(h',r,t')^{*}_{ENT} = \argmax_{(h',r,t') \in Neg)} -  \sum_{i}{\mathds{P}(y_i | (h',r,t')) log \mathds{P}(y_i|(h',r,t'))}$$
Since we have a binary classification with $y_i \in \{0,1\}$:\\
$$= \argmax_{(h',r,t') \in Neg)} - \mathds{P}(y = 1| (h',r,t')) log \mathds{P}(y = 1|(h',r,t'))$$
$$- \mathds{P}(y = 0| (h',r,t')) log \mathds{P}(y = 0|(h',r,t'))$$
$$= \argmax_{(h',r,t') \in Neg)} - \mathds{P}(y = 1| (h',r,t')) log \mathds{P}(y = 1|(h',r,t'))$$
$$- (1 - \mathds{P}(y = 1|(h',r,t') log(1 - \mathds{P}(y = 1|(h',r,t'))$$
To obtain the probabilities for a triple of being positive ($y=1$) we define
\begin{equation}
    \mathds{P}(y = 1|(h, r, t)) := \frac{Generator\_Score(h, r, t) - score_{min}}{score_{max} - score_{min}} \in [0, 1]
\end{equation}
and accordingly the probability of a triple to be negative ($y=0$) as
\begin{equation}
    \mathds{P}(y = 0|(h, r, t)) := 1 - \mathds{P}(y = 1|(h, r, t)) \in [0,1]
\end{equation}


\begin{figure}
    \centering
    \begin{minipage}{.33\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/entropy_graph.PNG}
    \end{minipage}%
    \begin{minipage}{.33\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/least_confident_graph.PNG}
    \end{minipage}
    \begin{minipage}{.33\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/least_confident_graph.PNG}
    \end{minipage}%
    \caption{Uncertainty measured by (a) Entropy, (b) Least Confident and (c) Smallest Margin.}
    \label{fig:test}
\end{figure}
