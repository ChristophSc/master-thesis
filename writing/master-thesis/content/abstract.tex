% !TEX root = ../my-thesis.tex
%
\pdfbookmark[0]{Abstract}{Abstract}
\addchap*{Abstract}
\label{sec:abstract}

Knowledge graphs present an incomplete knowledge repository of the world.
The information are stored through a connective structure of entities and relations.
To simplify the manipulation as well as preserving the inherent structure of a knowledge graph, entities and relations are embedded by knowledge graph embeddings in a continuous low-dimensional vector space.
Learning these embeddings requires the distinction between positive and negative triples.
Since only positive information are stored in knowledge graphs, 
there are several training types available to find negative examples, one of these is negative sampling. 
Thus, common used negative sampling approaches provide low quality negative examples.
As a result, embedding learning suffers from a too simple distinction between positive and negative instances, which has a direct impact on downstream tasks.
In many areas of machine learning, such as active learning, sampling through uncertainty offers the possibility of sampling particularly informative instances for a model and thus making the learning process more efficient.
Therefore, in this thesis we want to investigate the inclusion of uncertainty information in the negative sampling process as well.
Therefore, several methods of sampling by uncertainty are analyzed and, subsequently, applied in a negative sampling approach.

\vspace*{20mm}

{\usekomafont{chapter}Abstract (Deutsch)}
\label{sec:abstract-german}


