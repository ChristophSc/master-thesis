\textbf{KINSHIP Dataset}
\label{subsubsec:uncertainty_kinship}\\
%
A significant increase can also be seen in the progression of the MRR learning curve on the \kinship data set with both approaches, but the MRR value remains constant with \usgan after reaching the maximum (\Autoref{fig:advtrain_kinship_random_vs_uncertainty}).
With the original \kbgan approach, however, it drops again for all model pairs.
However, the maximum MRR values of \kbgan cannot be surpassed by the new approach \usgan p.
The situation is different, however, for the Hit@10 values.
These exceed the maximum value of the original approach with all model pairs.
\begin{figure}[H]
    \centering
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/random/kinship/1k_epochs/random_kinship_mrrs.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/uncertainty/max_distribution/entropy/kinship/1k_epochs/uncertainty_kinship_mrrs.png}
    \end{minipage}
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/random/kinship/1k_epochs/random_kinship_hit10.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/uncertainty/max_distribution/entropy/kinship/1k_epochs/uncertainty_kinship_hit10.png}
    \end{minipage}%
    \caption{Adversarial training on \kinship dataset. 
    Left Figures show sampling negative triples with \origsampling, right figures show \ussoftmax with entropy uncertainty metrics.
    Shown are validation Hit@10 and MRRs for 1000 epochs.}
    \label{fig:advtrain_kinship_random_vs_uncertainty}
\end{figure}

Whereas in the original approach losses increase after reaching a minimum, in the new approach they initially decrease and then stagnate (\Autoref{fig:advtrain_kinship_losses_rewards}).
While the progression of rewards in the original approach is identical for all model pairs, it behaves differently in the new \usgan approach.
There, the courses with a \transe discriminator look similar, but those with a \transd discriminator decrease from the beginning of the training.
Thus, in \usgan sampling approach \transd seems to be better able to recognize the negative triples as such and therefore assigns them a high scoring value.
\begin{figure}[H]
    \centering
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/random/kinship/1k_epochs/random_kinship_losses.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/uncertainty/max_distribution/entropy/kinship/1k_epochs/uncertainty_kinship_losses.png}
    \end{minipage}
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/random/kinship/1k_epochs/random_kinship_rew.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/uncertainty/max_distribution/entropy/kinship/1k_epochs/uncertainty_kinship_rew.png}
    \end{minipage}%
    \caption{Comparison of training losses and rewards over 1000 epochs on \kinship dataset.
    Left Figures show losses and rewards of \origsampling and right Figures show losses and rewards of \ussoftmax.}
    \label{fig:advtrain_kinship_losses_rewards}
\end{figure}