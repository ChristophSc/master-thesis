\section{Evaluation of the Uncertainty Metrics}
\label{ch:evaluation:sec:evaluation_metrics}

In the previous section, the two uncertainty sampling methods were only compared with the uncertainty metric entropy.
Since \ussoftmax was found to be a slightly better sampling method, this section now compares and evaluates the different uncertainty metrics entropy, least confidence, margin of confidence and ratio of confidence with \ussoftmax. 
These are also analysed for the four different data sets in \Autoref{subsec:metrics_umls} to \ref{subsec:metrics_fb15k237}.

\input{content/chapters/05_evaluation/sections/03_metrics/01_metrics_umls}

\input{content/chapters/05_evaluation/sections/03_metrics/02_metrics_wn18rr}

\input{content/chapters/05_evaluation/sections/03_metrics/03_metrics_wn18}

\input{content/chapters/05_evaluation/sections/03_metrics/04_metrics_fb15k237}

\subsubsection{Conclusion of Uncertainty Sampling Metrics}
\label{subsubsec:evaluation_metrics_conclusion}

On all datasets there is no significant difference between uncertainty metrics entropy, least confidence, confidence margin and confidence ratio.
In most cases maximum is almost reached after 100 to 150 epochs, after this learning stagnates or improves slowly.
Regarding rewards all uncertainty metrics have tje same curves, but rewards are different between model pairs with \transe and \transe discriminator model.
Since none of the uncertainty metrics achieves a significant better result than the other ones, we choose standard uncertainty metrics entropy.
Therefore, \ussoft with entropy metrics is compared to \origsampling in next section.