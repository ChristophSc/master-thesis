\section{Experimental Setup}
\label{ch:evaluation:sec:experimental_setup}
%
This section presents the experimental setup under which our evaluations took place.
This includes the embedding models, data sets, evaluation protocols but also implementation details.
To allow the best possible comparison with the original \kbgan approach, many of the settings and parameters are chosen identically.

\textbf{Embedding Models}\\
To allow a better comparison between Sampling by Uncertainty and original sampling, we train with the same models chosen by \kbgan.
These are the models \textsc{DistMult} and \textsc{Complex} for the generator component and the distance-based models \textsc{TransE} and \textsc{TransD} for the discriminator component.

\textbf{Datasets}\\
The results are evaluated and described on four common knowledge completion datasets  \textsc{UMLS}, \textsc{WN18RR}, \textsc{WN18} 
and \textsc{FB15k237} in this chapter.
Additionally, these were also carried out on the \kinship, \textsc{FB15k} and \textsc{Yago3-10} datasets.
However, as the results of these are very similar to the other four datasets and do not provide any additional information for the inclusion of uncertainty, the results and evaluation figures can be found in the appendix in \Autoref{app:results}.

While \textsc{UMLS} contains a relatively small dataset and is used for initial validations and testing of the different approaches.
Due to the small amount of data, these could also be tested on the local computer with low runtimes.
Once the tests on \textsc{UMLS} dataset were successful, it was possible to work with the other, larger datasets.
The significantly higher number of entities and relations resulted in longer runtimes.
\input{content/chapters/05_evaluation/datasets_table}
For this reason, these evaluations took place on the $PC^2$ servers.
\textsc{WN18RR} is a subset of \textsc{WN18} \textsc{WN18RR} and removes reversing relation, which increases the difficulty of reasoning dramatically \cite{cai2017kbgan}.
\textsc{FB15k-237} is a subset of \textsc{FB15k} and does not contain redundant relations which are present in \textsc{FB15k}.
These datasets are commonly used in knowledge graph research so their evaluation allows us to compare them with state-of-the-art approaches.
Statistics of datasets with the number of relations and entities, heads, and tails are shown in \autoref{tab:datasets}. 
In addition, the size of the training, validation, and test set is given.
        
\textbf{Evaluation Protocols}\\
As described in \cite{Ruffinelli2020You},
\ac{KGE} models are usually trained and evaluated by a multi-relational link prediction for \acp{KG}.
Based on the information in a \ac{KG}, its goal is to predict true but unobserved triples.
For this evaluation task, entity ranking is typically used.
After partitioning data into a set of training, validation, and test, for a given triple $(h,r,t)$ which is unseen during training potential answers for either missing head or missing tail are ranked by their score in descending order.
Additionally, since some triples might already be seen in training, validation, or test set, a filtering option is applied.
Therefore, triples that have been seen in training, validation, or test set are filtered out from ranking.
Subsequently, common evaluation metrics MRR and Hit@10 are used which return values $\in [0,1]$ where is the worst and 1 is the best result.
Therefore, the current learning process and embeddings can be evaluated and compared to other embedding models.

\textbf{Implementation Details}
In the original \kbgan approach, the models are first pre-trained individually over 1000 epochs on the corresponding data set before the actual \ac{GAN} training takes place.
In the course of our tests, we found that the adversarial training learns quickly and achieves good results even without pre-training the individual models.

As example, \Autoref{fig:original_pretrained_advtrain} shows adversarial training process of \textsc{FB15k-237} for 5000 epochs with the original sampling approach from \kbgan and pre-trained  generator and discriminator models.
\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/pretrained/random/fb15k237/gan_train_random_fb15k237_mrrs.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/pretrained/random/fb15k237/gan_train_random_fb15k237_hit10s.png}
    \end{minipage}
    \caption{Evaluation of Adversarial training on \textsc{FB15k-237} dataset.
    All models for generator as well as discriminator are pre-trained.
    Figures show validation MRRs and Hit@10s for 5000 epochs with \origsampling.}
    \label{fig:original_pretrained_advtrain}
\end{figure}
In this and many other learning processes on other data sets, it can be seen that evaluation metrics MRR and Hit@10 often drop at the beginning and then rise again.
This can be explained by the fact that during pre-training, the models are trained separated and independently.
In adversarial training, however, they learn together, so the models first have to understand each other.
Only when this has happened do the evaluation metrics rise again.

For comparison, an identical training was performed in \Autoref{fig:original_not_pretrained_advtrain}, where the only difference was that the models were not pre-trained.
\begin{figure}
    \centering
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/random/fb15k237/epochs5000/random_fb15k237_mrrs.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
      \centering
      \includegraphics[width=0.9\linewidth]{figures/results/gan_train/not_pretrained/random/fb15k237/epochs5000/random_fb15k237_hit10.png}
    \end{minipage}
    \caption{Evaluation of Adversarial training on \textsc{FB15k-237} dataset without pre-trained models.
    Figures show validation MRRs and Hit@10s for 5000 epochs with Original Sampling.}
    \label{fig:original_not_pretrained_advtrain}
\end{figure}
As can be seen, both training courses achieve MRRs of around 27\% and Hit@10s of around 45\%.
Although all model combinations in the second case were not pre-trained, they also achieve an MRR of approximately 26\% and a Hit@10 of about 44\% after 1000 epochs, just like the pre-trained models.
In addition, especially the training of the first 1000 epochs without pre-training seems to be more constant than adversarial training with pre-trained models.
For this reason, in the following sections, we will present the evaluation without pre-training, i.e. training from scratch.
Nevertheless, the results of pre-training and the subsequent adversarial training on pre-trained models can be found in the appendix (\autoref{app:results}).

Additionally, in the original approach, adversarial training takes place for 5000 epochs.
However, during the evaluation, it was found that in the case of adversarial training, the first 1000 epochs produced the greatest improvements in the discriminator model.
This was especially the case for training without pre-trained models.
For this reason, in our evaluation, we will focus on the first 1000 epochs.

For the evaluation, the parameters shown in \autoref{tab:evaluation_parameter} were defined.
\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \toprule
        
        \textbf{Parametername} & 
        \textbf{Value} & 
        \textbf{Description} \\
    
        \midrule
         n\_epoch & 1000 & Number of epochs for adversarial training\\
         n\_batch & 100 & Number of batches for training \\
         
         valid\_batch\_size & 100 & Size of each batch for validation and test set\\
         epoch\_per\_test & 50 & Defines after how many epochs a validation should \\
         &  & take place on the validation set \\
         n\_sample & 20 & Number of negative triples in set Neg \\

        % temperature & 1.0 & MISSING\\
        margin $\gamma$ & 3 & Margin of marginal loss function for discriminator model\\
        dimension k & 50 & Number of dimensions of embeddings \\ 
        optimizer & Adam & Self-adaptive optimization method \\

        \bottomrule
    \end{tabular}
    \caption{Table of parameter for evaluation runs which contains parameter names, their values and a description of each parameter.}
\label{tab:evaluation_parameter}
\end{table}