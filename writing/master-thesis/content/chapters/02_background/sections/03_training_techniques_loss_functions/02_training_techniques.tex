\subsection{Training Techniques}
\label{subsec:training_techniques}
%
Among all \ac{KGE} models, three commonly used approaches are used for training and differ mainly in the way how negative examples are generated \cite{Ruffinelli2020You}:
\begin{itemize}
    \item  
    \textbf{Negative Sampling}:
    In negative sampling, a set of (pseudo-) negative triples are generated by perturbing the subject, relation, or object for each positive triple \triple{h}{r}{t}.
    Optionally each obtained negative triple is verified, if it exists in the training \ac{KG} (false negative triples).
    
    \item  
    \textbf{1vsAll}:
    The 1vsAll training approach omits sampling by perturbing subject and object positions for all positive triples from a \ac{KG}, even if these negative triples exist as positive triples.
    In comparison to the negative sampling approach, it is generally more expensive but feasible if the number of entities is not excessively large.
        
    \item  
    \textbf{KvsAll}: 
    The KvsAll training type is divided into two different steps:
    At first, batches from non-empty rows are constructed instead of from individual triples.
    Secondly, all of these generated triples are labeled as either positive or negative triples.
\end{itemize}
\clearpage