\subsection{Epistemic and Aleatoric Uncertainty}
\label{subsec:epistemic_and_alreatoric_uncertainty}
%
\Ac{EAU} is based on the use of relative likelihoods \cite{nguyen2021howtomeasure}. 
\Ac{EU} samples an instance for which both the positive and the negative class appear to be plausible, while \ac{AU} samples instances where none of the classes is supported.
For a set of training data $D = \{(x_i, y_i)\}_{i=1}^{N}$ the normalized likelihood of a model $h_{\theta}$ is defined as
\begin{equation}
\pi_{\Theta}(\theta) = \frac{L(\theta)}{L(\theta^{ml})} = \frac{L(\theta)}{\max_{\theta'\in \Theta}{L(\theta')}}.
\end{equation} 
$L(\theta) = \prod_{i=1}^{N}{p_{\theta}(y_i | x_i)} $ is the likelihood of $\theta$, and $\theta^{ml} \in \Theta$ the maximum likelihood estimation on training data \cite{nguyen2021howtomeasure}.
Given $\pi_{\Theta}(\theta)$ and an instance x, the degrees of support or plausibility of  classes 0 and 1 are defined as \cite{nguyen2021howtomeasure}:
\begin{equation}
\pi(0 | x) = \sup_{\theta \in \Theta} \min \bigg[ \pi_{\Theta}(\theta), p_{\theta}(0 | x) - p_{\theta}(1 | x)\bigg]
\end{equation} 
and
\begin{equation}
\pi(1 | x) = \sup_{\theta \in \Theta} \min \bigg[ \pi_{\Theta}(\theta), p_{\theta}(1 | x) - p_{\theta}(0 | x)\bigg].
\end{equation} 
Accordingly, $\pi(1 | x)$ is high if and only if a positive class is much stronger supported than the negative class and vice versa for $\pi(0 | x)$ by a highly plausible model  \cite{nguyen2021howtomeasure}.
Therefore, uncertainty exists due to either influence of both classes or a lack of knowledge \cite{nguyen2021howtomeasure}. 

With this definition for degrees of support for positive and negative classes, epistemic uncertainty $u_e$ is defined as \cite{nguyen2021howtomeasure}
\begin{equation}
u_e = \min \bigg[ \pi(1 | x), \pi(0 | x) \bigg]
\end{equation}
and aleatoric uncertainty $u_a$ as
\begin{equation}
u_a = 1 - \max \bigg[ \pi(1 | x), \pi(0 | x) \bigg].
\end{equation}

In general, it can be said that epistemic uncertainty returns uncertainty within a single model's prediction and aleatoric uncertainty the uncertainty across multiple predictions \cite{human-in-the-loop}.
As an example, \Autoref{fig:differences_aleatoric_epistemic} shows two different classes with label A and label B.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.85\textwidth]{figures/uncertainty_differences.PNG}
  \caption{Difference between aleatoric and epistemic uncertainty (obtained from \cite{human-in-the-loop}).}
  \label{fig:differences_aleatoric_epistemic}
\end{figure}
Some of the instances have already been labeled, others not yet.
Furthermore, a total of five different decision boundaries from five different predictions can be identified.
The first marked instance is close to the decision boundaries of all five predictions.
Therefore, we have high epistemic uncertainty since all models are uncertain about how to label the first marked instance in the figure.
Thus, we have low aleatoric uncertainty since the decision boundaries of all models are close together.
For the second instance, all models are certain about how to label it so epistemic uncertainty is low.
In contrast, the variance of distance to decision boundaries is very high, which results in high aleatoric uncertainty.
Consequently, for the third instance both, aleatoric and epistemic uncertainty is high.