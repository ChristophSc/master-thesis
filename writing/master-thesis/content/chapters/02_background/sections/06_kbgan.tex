\section{KBGAN} 
\label{sec:kbgan}

\kbgan plays a central and important role in the context of this work.
Thus, this approach is described for a precise understanding at this point.
The embedding is learned with an adversarial training process which consists of two components: a generator and a discriminator.
This process of \kbgan is depicted in \autoref{fig:overview} and described as follows:
\begin{figure*}[t]
  \centering
    \includegraphics[width=0.95\textwidth]{figures/kbgan_original.png}
  \caption{An overview of the \textsc{kbgan} framework (based on: \cite{cai2017kbgan}).}
  \label{fig:overview}
\end{figure*}

\begin{enumerate}
    \item 
    At first, a set of sampled corrupted triples $Neg(h,r,t)\subset\{(h',r,t)|h'\in\mathcal{E}\}\cup\{(h,r,t')|t'\in\mathcal{E}\}$ is created.
    Ideally, this set would contain all possible negatives \cite{cai2017kbgan}.
    Since \acp{KG} are usually highly incomplete, some of them might be false negatives which are actually true facts.
    Therefore, \kbgan uniformly samples only $N_s$ entities and replaces either head entity \texttt{h} or tail entity \texttt{t} of a given positive triple \triple{h}{r}{t}.
    In comparison to the number of all possible negatives, $N_s$ is a relatively small number \cite{cai2017kbgan}.
    
    \item 
    Negative triples from $Neg$ are given to the generator G as input.
    
    \item 
    The generator G receives all negative triples from negative triple set $Neg$ and scores them with the scoring function $f_G$ of G.
    Since G is a tensor factorization-based \ac{KGE} model like \distmult or \complex, negative triples with higher scores indicate a higher plausibility to be true.
    The scores are passed to the softmax function, which assigns a sampling probability $p_i$ for each negative triple $l_i = (h_i, r_i, t_i)$:
    \begin{equation} \label{eq:origsampling}
        p_i = \frac{\exp{f_G(l_i)}}{\sum_{j=1}^{N_s}{\exp{f_G(l_j)}}} \in [0,1]
    \end{equation}
    Therefore, we obtain a probability distribution $p_G(h',r,t'|h,r,t)$ where each negative triple \triple{h'}{r}{t'} a probability is assigned based on given positive triple \triple{h}{r}{t} and all sampling probabilities sum up to 1.
    
    \item
    According to this probability distribution one negative triple is sampled.
    Since from generator G negative triples with higher scores were assigned a correspondingly higher sampling probability, it is more probable to sample a negative triple which achieved a high score in generator.

    \item 
    Afterwards, the sampled negative triple \triple{h'}{r}{t'} and corresponding positive triple \triple{h}{r}{t} are given to discriminator D.
    
    \item 
    Discriminator D receives as input both the sampled negative triple \triple{h'}{r}{t'} and the ground truth triple \triple{h}{r}{t}.
    It underlying \ac{KGE} model scores with its scoring function $f_D$ scores both triples, the received positive and negative one.
    Since D is a translation-based model, it returns distances where lower distance indicate a higher likelihood of truth and vice versa \cite{cai2017kbgan}.
    Therefore, the distance of received positive triple \triple{h}{r}{t} should be small and if it was a good negative triple \triple{h'}{r}{t'} , its distance should be small as well.
     
    \item 
    The training objective of D is a marginal loss function, because models based on these can  benefit the most from high quality negative examples .
    Therefore, the marginal loss is calculated from both distances, the positive and the negative triple one:
     \begin{equation}
        L_{marginal}
        =\sum_{(h,r,t)\in\kg}[f(h,r,t)-f(h',r,t')+\gamma]_+ 
        = \sum_{(h,r,t)\in\kg}[d_p-d_n+\gamma]_+ 
    \end{equation}
    where $d_p = f(h,r,t)$ is the distance of positive triple \triple{h}{r}{t} and $d_n = f(h',r,t')$ the distance of the negative triple  \triple{h'}{r}{t'}.
    Therefore, the better the sampled negative triple is, the lower is its distance and a consequently lower marginal loss is achieved.
    
    \item 
    To give G feedback for the sampled negative triple \triple{hâ€™}{r}{t'} a reward $r$ is send back to G, which is defined as
    \begin{equation}
        r = -f_D(h',r,t') \in \mathbb{R}^-
    \end{equation}
    since $f_D(h,r,t) \in \mathbb{R}^+$.
    Therefore, the lower distances are achieved with sampled negative triples, the higher the reward.
    Consequently, the objective of G can be formulated as maximizing the expectation of negative distances:
    \begin{equation}
        R_G=\sum_{(h,r,t)\in\kg}\mathbb{E}[-f_D(h',r,t')]
    \end{equation}
    
    \item
    This process ends until the set number of epochs has been reached.
    
\end{enumerate}
The dynamic distribution of negative triples is determined through this procedure of the adversarial training, 