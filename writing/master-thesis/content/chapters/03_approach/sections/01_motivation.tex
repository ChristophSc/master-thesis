\section{Motivation} 
\label{sec:motivation}
% 1) Presentation of my idea
% - the origin of my idea
% - Reasons for Uncertainty - advantages and expected results
% - Why did I choose KBGAN (Sampling Negatives from Dynamic Distribution) 
%   as the basis for my approach
% - disadvantages of KBGAN that I want to solve
% - why does uncertainty sampling can solve them?
As we have seen in \Autoref{sec:training_techniques_and_loss_functions}, there are several ways to learn a \ac{KGE}.
Many models learn embeddings by distinguishing positive triples from a \ac{KG} and negative triples generated by negative sampling.
Accordingly, although many models rely on negative sampling, most of these approaches provide only negative triples with insufficient quality \cite{qiannegative}.
With our approach, uncertainty information is incorporated in a \ac{KGE} learning process to sample negative triples that are more informative and more valuable for the embedding model.
Informative at this point means particularly interesting triples for the embedding model because those are difficult to classify as positive or negative triples.
Therefore they help the embedding model the most to differentiate negative from positive triples.

% why uncertainty sampling can solve current problems
% Uncertainty Sampling in other approaches -> results
Including uncertainty in various procedures and trainings of machine learning models has already yielded promising results in recent work.
For example, this makes active learning more efficient by only querying particularly informative instances in the labeling process.
There are many other active learning query frameworks, but uncertainty sampling is the most common one \cite{Settles2009ActiveLL}.
In addition, it is easier to implement than some other frameworks, since it does not require to train multiple models as it is the case with query-by-committee  \cite{Settles2009ActiveLL}.
Nevertheless, uncertainty sampling provides promising results for many active learning scenarios and is therefore used for our approach to sample from a negative triple set.
Besides this, in the world of uncertain \acp{KG}, confidence scores for positive triples have already been included in a \ac{URGE} \cite{UKGE}.
Accordingly, we also want to incorporate uncertainty information in an embedding learning process with negative sampling.

% Why did I choose KBGAN (Sampling Negatives from Dynamic Distribution) 
The basic idea of sampling by uncertainty is to select particularly interesting negative triples from an already existing set of negative triples.
Since most embedding models from the three negative sampling categories (\Autoref{subsec:negative_sampling_methods}) can sample negative triples, they can also create a negative triple set,
Accordingly, any approach of the three categories can be selected and extended by uncertainty information.
Since the dynamic distribution-based approach \kbgan already creates such a set of negative triples and captures the distribution of negative triples dynamically, we have decided to extend this approach.
Therefore, instead of sampling only based on scoring values of negative triples, our approach will sample them based on uncertainty scores.
Since this new approach is based on a \ac{GAN} with an adversarial learning process where negative triples are sampled by uncertainty and given to the discriminator, we call this approach \textbf{\underline{U}ncertainty \underline{S}ampling \underline{G}enerative \underline{A}dversarial \underline{N}etwork (\textsc{USGAN})}.
