\section{Selection of an Uncertainty Sampling Framework} 
\label{sec:selection_of_an_uncertainty_sampling_type}

% review of all frameworks
In the literature we have several types of uncertainty at our disposal.
As described in \Autoref{sec:uncertaintysampling}, there are three different frameworks for measuring uncertainty:
\ac{EBU}, \ac{EAU} and \ac{CU}.
These frameworks for calculating uncertainty are based on different viewpoints, but all of them are based on a classification problem of two or more classes.
In \ac{EBU} we consider uncertainty within a model by looking at the individual features of a model and if they provide evidence for classes.
This can be either very many (\textit{conflicting-evidence}) or only a few features (\textit{insufficient-evidence}) which are indicative for the respective classes.
In contrast, \ac{EAU} considers \textit{epistemic uncertainty} within a single modelâ€™s prediction, and \textit{aleatoric uncertainty} across multiple model predictions \cite{human-in-the-loop}.
Since \textit{credal uncertainty} differentiates between the reducible and irreducible part of the uncertainty in a prediction and the domination of one class over the other, we calculate uncertainty among multiple models as well.

% determination of one framework
In this adversarial training process, negative triples are first passed to the generator, which calculates scores for them based on the current embeddings.
subsequently, based on these scores, one of these negative triples is sampled and given to the discriminator.
Therefore, we only have information about the embeddings of the generator model and all negative triple scores.
We do not have any additional features for the sampling process.
For this reason, we will first take the point of view of epistemic uncertainty from \ac{EAU}.
If we add further models for a classification between negative and positive triples in the later process or add additional features, the other viewpoints aleatoric uncertainty, \ac{EAU} and \ac{CU} can be taken as well.


%- literature on aleatoric uncertainty tends to focus on the optimal types of ensembles and dropouts \cite{human-in-the-loop}

%for epistemic uncertainty the literature focuses
%on improve accuracy on probability distributions within a single model \cite{human-in-the-loop}

%-> we have a probability distribution from which is sampled

%epistemic
%-> philosophy: 
%due to limited data and knowledge. 
%Given enough training samples, epistemic uncertainty will decrease.
%historically: meant lack of knowledge
%model uncertainty
%-> machine learning:
%-> literature on epistemic uncertainty tends to focus
%on getting more accurate probability distributions from within a single model

%aleatoric:
%-> philosophy:
%arising from the natural stochasticity of observations
%cannot be reduced even when more data is provided
%historically meant inherent randomness
%data uncertainty
%-> machine learning: