\section{Objectives}
\label{sec:objectives}

% OBJECTIVE + HYPOTHESIS
Inspired by uncertainty sampling in active learning, uncertainty information is incorporated into an existing negative sampling process from embedding learning.
Unlike previous approaches, we thus do not sample a negative triple which is closest to a positive one, but the one where the embedding model is most uncertain.
Therefore, the sampled instances can be hard negative examples, which are close to the corresponding positive triple, and therefore difficult to discriminate, but also other negative triples that are valuable for the embedding model.
By implementing a new sampling method, more informative negative triples are expected to be sampled and consequently, have a positive impact on a negative sampling and training process.
This could be an acceleration of the learning process such as achieving the same accuracies with fewer epochs, the same accuracies with less training time, or achieving better overall accuracy.

% CONTRIBUTIONS
This thesis makes the following contributions:
First, existing approaches of negative sampling are checked and analyzed.
In addition, different uncertainty sampling techniques of active learning are verified.
Subsequently, these approaches are reviewed for their applicability to negative sampling.
Based on this, a new negative sampling approach is created.
After implementation of uncertainty sampling, an evaluation is performed by testing the new approach on seven different \ac{KG} datasets.
Due to the partly large amount of data and correspondingly longer execution times, \ac{PC2}\footnote{\url{https://pc2.uni-paderborn.de/}} is used for this purpose.
Finally, the results are compared with existing methods to conclude the approach of \textbf{Sampling of Negative Triples for Knowledge Graph Embeddings by Uncertainty}.








