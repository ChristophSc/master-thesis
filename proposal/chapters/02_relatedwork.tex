\chapter{Related Work}
\label{ch:relatedwork}

\paragraph{Knowledge Graph Embeddings} 
are low-dimensional representations of the entities and relations in a \ac{KG}. 
Numerous methods have been developed in the last few years, all of them define a different score function to measure the distance between entities relative to their relation.
Depending on the dimensionality of the embedding space and which types of relations should be embedded, a different embedding can be chosen.
While some of them support only symmetric relations, others support antisymmetric ones as well. 
Besides this, the types of relations in a \ac{KG} differ from each other.
We can differentiate between 1-to-1, 1-to-N, N-to-1, and N-to-N relations.
Overall, all the embedding methods can be separated by three different aspects \cite{electronics9050750}.
How they represent entities and relations, define the scoring function and optimize the ranking criterion
On the basis of this, two different categories are derived:
\textit{Triplet Fact-Based Representation Learning Models} and \textit{Description-Based Representation Learning Mode} \cite{electronics9050750}.

\textit{Triplet Fact-Based Representation Learning Models} are separated into three groups:
\begin{enumerate}
    \item 
    \textit{Translation-Based Models}  which are based on word embedding algorithms. 
    Example models are e.g. TransE, TransH, TransR, and TransD, RotatE,
    
    \item 
    \textit{Tensor Factorization-Based Models}
    RESCAL, DistMult, ComplEx,HolE,
    
    \item 
    \textit{Neural Network-Based Models}
    ConvE, HypER, ConEx, ConvQ, ConvO
\end{enumerate}

\paragraph{Negative sampling methods}  

Most of these graph representation learning methods can be unified within a \ac{SampledNCE} framework comprising an encoder that generates node embeddings by learning to distinguish positives and negatives pairs \cite{MCNS}.
Groups of Negative sampling methods are:
\begin{itemize}
    \item 
    \textbf{Degree-based negative sampling} methods like Power of Degree \cite{MikolovSCCD13}, \ac{RNS}\cite{Dupre2018Word2vec} and \ac{WRMF} \cite{Hu2008Collaborative} and can be summarized as $p_n(v) \propto deg(v)^\beta$.
    The probability is given by e.g. weighting the different nodes which leads to a 
    static and inconsiderate to the personalization of nodes \cite{MCNS} because the probability of a node being samples is not changed later on.
    Additionaly, in the quality of negative samples generated by random sampling is  often poor \cite{cai2017kbgan}.
    
    \item 
    \textbf{Hard-samples Negative Sampling} methods try to find negative examples with high positive probabilities and the best negative samples are found by rejection \cite{MCNS}. 
    In comparison to the previously presented Negative Sampling group, 
    different negative samples are created and ranked by specified ranking functions.
    These ranks are created by e.g. \ac{BPR}, \ac{WARP} or a language model depending on how similar two given words are. 
    Within this group, approaches like\ac{PinSAGE} \cite{PinSAGE}, sampling-max (\ac{DNS}) \cite{DNS} and \ac{WARP} \cite{WARP} can be mentioned.
    
    \item 
    \textbf{\ac{GAN}-based Negative Sampling} was originally proposed for
    generating samples in a continuous space such as images \cite{cai2017kbgan}.
    In recent years it was used for negative sampling approaches which achieved state-of-the-art accuracies. 
    \ac{GAN}-based approaches consist of two components:
    a generator and a discriminator. 
    While the generator adaptively generates hard negative samples according to the reward from the discriminator, the discriminator itself learns to embed the \ac{KG} using the negative triplets from the generator \cite{IGAN}.
    
    
    %\item 
    %MUST STILL BE ASSIGNED TO GROUPS:
    %\cite{alam2020affinity}: 
    %1) Typed Sampling
    %2) Relational Sampling
    %3) Distributional Negative Sampling
    %--> \ac{ADNS}
    %4) \ac{MCNS}
\end{itemize}

\paragraph{\textbf{Standard evaluations for knowledge graph embedding models:}}  
To evaluate the \ac{KGE} models, different metrics are available.
Some most commonly used are the following metrices \cite{kotnis2017analysis}:
\begin{itemize}
    \item 
    \ac{MRR} which is defines as
    $$MRR = \frac{1}{N} \sum_{i=1}^{N}\frac{1}{rank_i}$$
    computes the average of the reciprocal ranks \cite{zhang2021efficient}
    
    \item 
    hits@k which calculates the percentage of appearance in the top-10
ranking \cite{zhang2021efficient}.
    $$hits@K = \frac{|\{i | rank_i < K\}|}{N}$$
    where $rank_i$ is the rank of the positive instance $i$ predicted by the
    model with respect to the negative samples and usually $k \in \{1,3,5,10\}$.
    The 
\end{itemize}

\paragraph{\textbf{Standard evaluations for knowledge graph embedding models:}}
The main idea of Active Learning is that learning algorithms are allowed to choose the data from which it learns and aims to perform better with less training.
It comprises two components: the active learner and a oracle/user.
While the active learner aims to achieve high accuracy, the oracle labels the instances received by the active learner.
With this approach, Active Learning usually attempts to overcome the labeling bottleneck to minimize the cost of obtaining labeled data.
Active Learning can be divided into three main settings \cite{Settles2009ActiveLL}:
\begin{itemize}
    \item 
    In \textbf{membership query synthesis} an active learner produces an example that it would like the oracle to label the instance.
    This requires the active learner to be able to capture the data distribution and to create reasonable instances.
    
    \item 
    Second active learning strategy  \textbf{pool-based active sampling} requires a large collection of unlabeled data.
    In comparison to stream-based selective sampling this setting evaluates and ranks the entire collection before selecting the best query.
    
    \item 
    The last strategy is \textbf{stream-based selective sampling} where obtaining unlabeled instances is inexpensive and the learner can decide whether or not to request its label.
    Typically, each unlabeled instance is drawn iteratively from the data source,
    With "informativeness measure", "query strategy" or from a region of uncertainty.
\end{itemize}


\paragraph{Active Learning}
\citeauthor{Settles2009ActiveLL} describes in its survey the different approaches of Active Learning \cite{Settles2009ActiveLL}.
The idea of Active Learning is to achieve greater accuracy with fewer labeled training instance by choosing the data from which it learns.
It is well-motivated in many modern machine learning problems, where we have an abundant amount of unlabeled data, but it is difficult, time-consuming or expensive to obtain labeled data.
For Active Learning three different settings are differentiated:
\begin{enumerate}
    \item \textbf{Membership Query Synthesis}
    In this setting the learner usually generates queries de novo, rather than those sampled from an an underlying distribution. 
    For example, the active learner rotates a given picture which is sent to and classified by the oracle.
    
    \item \textbf{Stream-Based Selective Sampling}
    is an alternative to synthesizing queries and quieries samples my selective sampling with the key assumption that obtaining an unlabeled instance is unexpensive.
    it is also called stream-based or sequential active learning, since it is done in an iterative manner.
    
    \item \textbf{Stream-Based Selective Sampling} is based on the assumption that we have a large collection of unlabeled data which can be gathered at once.
    With this strategy, instances are queried according to an informativeness measure.
    It is closely related to Stream-Based Selective Sampling since the only difference is that the instances are queried at once and not iteratively.
\end{enumerate}



%- GAN-based approaches
%- discriminator takes the role as annotator, while generator provide negative %samples
%- the more difficult it is for discriminator to annotate a given triples as positive or negative, the higher the reward for the generator
%- models train each other
%- Baseline approaches: IGAN and KBGAN
%- randomly replace head or tail entity
%- NSCaching: 

%- infinite set of possible negative samples
%- random sampling does not generate informative negative examples, probably useless