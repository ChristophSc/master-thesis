\chapter{Solution}
\label{ch:solution}

% description and general introduction to solution
Our approach addresses the problem instability and degeneracy of the training process due to high variance and the non-guaranteed creation of large-gradient negative triples.
The training process is improved by adding more information in the sampling process and selecting negative examples that are more informative and therefore, more useful for the embedding model.
This is achieved by including Uncertainty Sampling in state-of-the-art approaches.
Since \ac{KBGAN} captures the dynamic distribution of negative samples, but suffers particularly from non-efficient Sampling, our first considerations are based on this approach.
However, it is also conceivable for other existing approaches with inefficient negative sampling process by replacing it with Uncertainty Sampling.

In general, in \ac{KBGAN} there are two different ways to improve the approach:
First, this can be achieved by improving the general quality of the negative examples in subset $Neg$.
Second, the learning process can be optimized by learning faster with less sampling which is addressed by Uncertainty Sampling.
Uncertainty Sampling originally comes from Active Learning.
Active Learning is originally well-motivated in many machine learning approaches where unlabeled data is abundant, but it is difficult, time-consuming, or expensive to obtain labeled data \cite{Settles2009ActiveLL}.
By Active Learning, we aim for greater accuracy with fewer labeled training instances by choosing the data from which we learn from \cite{Settles2009ActiveLL}.
In our case, we want to generate informative negative examples, which are used in the embedding model to obtain a good \ac{KGE} and achieve higher accuracies in the subsequent tasks. 
By integrating Uncertainty Sampling into Negative Sampling approaches, particularly interesting triples are sampled, i.e. those that are difficult to classify as positive or negative. 
In Uncertainty Sampling, an active learner queries the instances where it is most uncertain about how to label it \cite{Settles2009ActiveLL}.
If we use entropy-based Uncertainty Sampling in a binary classification problem like in our case, it is identical to choose the instance whose posterior probability of being positive is nearest to 0.5 \cite{Settles2009ActiveLL}.
Entropy is defined as \cite{Settles2009ActiveLL}:
\begin{equation}
    x^{*}_{ENT} = \argmax_{x} - \sum_{i}{\mathds{P}(y_i | x; \theta) log \mathds{P}(y_i|x; \theta)}
\end{equation}
In our scenario of negative sampling, since we have a binary classification between negative ($y=0$) and positive ($y=1$) triples, $<$ 0.5 represents a negative example and $\geq$ 0.5 a positive example.
The result is that we query examples that are close to 0.5, or in other words: we query hard negatives which are close to being positive.

The structure of our approach is illustrated in Figure \ref{fig:architecture}.
It can be seen that Uncertainty Sampling replaces the original sampling process by probability distribution.
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/architecture.png}
    \caption{Structure of our negative sampling approach including two components:
    A generator G which samples negative triples by Uncertainty Sampling and a discriminator D which scores the difference of positive triple $(h,r,t)$ and negative triple $(h',r,t')$ by given embedding score function $f_D$}
    \label{fig:architecture}
\end{figure}
In the original \ac{KBGAN} approach, a softmax function is applied to obtain probabilities of being sampled for each generated negative triple.
For Uncertainty Sampling, we need probabilties of each triple to be positive. 
Therefore, we need probabilities $\mathds{P}(y_i | x; \theta)$ for the classes $y_i \in \{0, 1\}$.
To incorporate more information in the score function than just the embedding of a triple, we want to extend the score function by several information about entities and relations in a \ac{KG}.
more information into the score function, we replace the original embedding function $f_G$ of the generator G in \ac{KBGAN} with the new score function $Generator\_Score$, which is defined as:
\begin{equation}
    Generator\_Score(h, r, t)=
    \begin{cases}
         \lambda_1 \text{PEER(\textit{h, r})} + \lambda_2 \text{POP(\textit{t})} + \lambda_3 \text{PIVO(\textit{h, t})} + \lambda_4 f_G(\textit{h, r, t})
         \\ \ \ 
         if\ \ \ \neg(\textit{h, r, t})
         \\ \\
         \lambda_1 \text{PEER(\textit{h, r})} + \lambda_4 \text{FRQ(\textit{r})} + \lambda_3 \text{PIVO(\textit{h, t})} + \lambda_4 f_G(h, r, t)
         \\ \ \ 
         if\ \ \ \neg \exists (\textit{h, r, \_})
         \\
    \end{cases}
\end{equation}
where $\lambda_i \in [0, 1]$ for $i \in [1,4]$ and $\neg (h, r, t)$ is a \textit{grounded negative statement} and is satisfied if $(h, r, t) \notin$ KG and $\neg\exists(h, r, \_)$ is a \textit{universally negative statement} which is satisfied if there exists no $t$ such that $(h, r, t) \in KG$ \cite{arnaout2020enriching}.\\
Assuming $\mathcal{T} \subset $ \ac{KG} is a set of positive triples and $\entities_{\mathcal{T}}$, $\relations_{\mathcal{T}}$ are its sets of entities and relations.
Additionally we have the function $peergroup(e) \subseteq \mathcal{T}$ which returns a set of peers for given entity $e \in \entities_{\mathcal{T}}$ by its embedding. 
Then the $Score$ function contains the following features from \cite{arnaout2020enriching} for peer groups and provides additional information about the relations and entities of triples:
\begin{itemize}
    \item 
    \emph{\ac{PEER}:} 
    Relative frequency of peers within a peer group that is related to different objects, e.g. 0.9 of persons are married. 
    \begin{equation}
        PEER(h,r) = \frac{|\{p | p \in peergroup(h), (p, r, \_) \in \mathcal{T}\}|}{|peergroup(h)|}
    \end{equation}

    \item
    \emph{\ac{POP}:} 
    The popularity of the tail entity $t$ in $\mathcal{T}$. 
    \begin{equation}
        POP(t) = \frac{|\{t | (\_, t, \_) \in \mathcal{T}\}|}{|\mathcal{T}|}
    \end{equation}

    \item 
    \emph{\ac{FRQ}:} 
    Frequency of a relation/predicate $r$ in $\mathcal{T}$. 
    \begin{equation}
        FRQ(r) = \frac{|\{r | (\_, r, \_) \in \mathcal{T}\}|}{|\mathcal{T}|}
    \end{equation}
    
    \item 
    \emph{\ac{PIVO}:} 
    Textual background information about an entities $h$ and $t$ and is a pivoting classifier like in \cite{arnaout2020enriching}.
    
    \item 
    \emph{$f_G$:} 
    $Score$ function of the \ac{KGE}  model from generator like in the original \ac{KBGAN} approach (e.g. \textsc{DistMult}  or \textsc{ComplEx}).
    
\end{itemize}

Input of the \ac{UCGAN} algorithm is a pre-trained generator G with parameters $\theta_G$ and score function $f_G(h,r,t)$, 
and a pre-trained discriminator D with parameters $\theta_D$ and score function $f_D(h,r,t)$.
The training process can be described in the following steps:
\begin{enumerate}
    \item 
    If $\mathcal{T}=\{(h,r,t)\}$ is the training set of positive fact triples, sample a mini-batch of data $\mathcal{T}_{batch} \subset \mathcal{T}$.
 
    \item  Calculate $Score$ (equation (2)) for all positive triples $(h, r, t) \in \mathcal{T}_{batch}$.
    \begin{equation}
        score_{max} := \argmax_{(h,r,t) \in \mathcal{T}_{batch}}{Score(h,r,t)}
    \end{equation}
    Assuming $(h,r,t)_{max}$ achieved the highest score, 
    it is considered to have a probability of being positive (y=1) of 1:
    \begin{equation}
        \mathds{P}(y = 1|(h, r, t)_{max}) := 1
    \end{equation}
    
    \item 
    Create a set of negative triples $Neg(h,r,t)=\{(h_i',r,t_i')\}_{i=1\dots N_s}$ by uniformly randomly sample $N_s$ negative triples by replacing head $h$ or tail entity $t$ for given positive triple $(h, r, t)$.
    
    \item 
    Calculate $Score$ of each triple $(h',r,t') \in Neg$, while $Score$-function (equation (2)).
    Remember triple $(h',r,t')_{min}$ which achieves the minimum negative score which is defined as
    \begin{equation}
        score_{min} := \argmin_{(h', r, t') \in Neg}{Score(h', r, t'))}
    \end{equation}
    In the next step, $score_{min}$ is the lower bound for the probability of a triple to be positive (y=1), so it is considered to be a probability of 0.
    \begin{equation}
        \mathds{P}(y = 1|(h', r, t')_{min}) := 0
    \end{equation}
    
    \item 
    To sample the negative triple $(h',r,t')^{*}_{ENT}$, we need to calculate the entropy-based uncertainty, which is defined as:
    $$(h',r,t')^{*}_{ENT} = \argmax_{(h',r,t') \in Neg)} - \sum_{i}{\mathds{P}(y_i | (h',r,t')) log \mathds{P}(y_i|(h',r,t'))}$$
    Since we have a binary classification with $y_i \in \{0,1\}$:\\
    $$= \argmax_{(h',r,t') \in Neg)} - \mathds{P}(y = 1| (h',r,t')) log \mathds{P}(y = 1|(h',r,t'))$$
    $$- \mathds{P}(y = 0| (h',r,t')) log \mathds{P}(y = 0|(h',r,t'))$$
    $$= \argmax_{(h',r,t') \in Neg)} - \mathds{P}(y = 1| (h',r,t')) log \mathds{P}(y = 1|(h',r,t'))$$
    $$- (1 - \mathds{P}(y = 1|(h',r,t') log(1 - \mathds{P}(y = 1|(h',r,t'))$$
    To obtain the probabilities for a triple of being positive ($y=1$) as we define
    \begin{equation}
        \mathds{P}(y = 1|(h, r, t)) = \frac{score(h, r, t) - score_{min}}{score_{max} - score_{min}} \in [0, 1]
    \end{equation}
    and accordingly the probability of a triple to be negative ($y=0$) as
    \begin{equation}
        \mathds{P}(y = 0|(h, r, t)) = 1 - \mathds{P}(y = 1|(h, r, t)) \in [0,1]
    \end{equation}
    
    \item 
    From this step on, everything is the same as the original \ac{KBGAN} approach:
    The generated negative triple $(h',r,t')$ as well as the positive triple $(h, r, t)$ are sent to the discriminator.
    
    \item 
    The discriminator distinguishes both triples by given scoring function $f_D$, which is usually a translation-based \ac{KGE} model like \textsc{TransE} or \textsc{TransD}.
    
    \item 
    The reward defined by $r = - f_D(h',r,t')$ of the current triple pair is calculated and added to the reward sum $r_{sum}$.
    
\end{enumerate}
These adversarial training steps are repeated until convergence, such that the generator improves the quality of sampled negatives and discriminator improves embedding over time.
Output of the \ac{UCGAN} algorithm is the adversarially trained discriminator and its embedding.

For the implementation of our prototype for our approach, we will use rather small datasets and start with \textsc{KINSHIP} and \textsc{UMLS}.
Subsequently, we want to compare our achieved accuracy with state-of-the-art approaches.
Therefore, we want to use \ac{MRR} and Hit@10 metrics on datasets \textsc{WN18}, \textsc{WN18RR}, \textsc{FB15K}, \textsc{FB15K237}, \textsc{YAGO3-10}.
Since these datasets are large and running algorithms on them are computationally expensive, we want to use Noctua-Server (or OCuLUS?) to fasten the learning process of our model.
Additionally, we will test the impact of our negative sampling approach on different embeddings with the given datasets and compare in which areas our method outperforms the current state-of-the-art approaches.
For this reason, we will use the most common embeddings from the three groups of embedding types:
\textsc{TransE}, \textsc{TransH} for \textit{Translation-Based Models}, \textsc{DistMult} and \textsc{ComplEx} for \textit{Tensor Factorization-Based Models}, and \textsc{ConvE} and \textsc{ConEx} for \textit{Neural Network-Based Models}.

% ---------------------------- OLD ----------------------------  

%These interesting and useful negative samples are subsequently used to learn the embedding.
%As described in the related work chapter, we have three different settings available for active learning:
%Since we do not know anything about the distribution of negative samples at the beginning, and we have a large pool of negative samples, it would be very time-consuming to rank each instance.
%For this reason, \textit{Pool-Based Active Learning} is the least appropriate for our scenario.
%So the decision if we chose \textit{Membership Query Synthesis} or \textit{Stream-Based Selective Sampling} depends on if we already have a negative sample pool or we have to create them de novo.
%For the former scenario we can select positive samples from the \ac{KG} and generate a negative sample by replacing the head or tail entity.
%With this approach the active learner would learn how to replace entities to create useful and informative negative samples.
%The latter setting of \textit{Stream-Based Selective Sampling} would already require an existing large pool of negative samples.
%This could be done by replacing head or tail entity randomly by any other entity of the \ac{KG} for a set of chosen positive samples.
%Since the setting of \textit{Membership Query Synthesis} seems to be less time-consuming and less-memory intense, this one meets our requirements more and, therefore, is used for our scenario.

%Each of the active learning settings evaluate the informativeness of unlabeled
%%instances, which is in our case the informativeness of negative samples \cite{Settles2009ActiveLL}.
%In the literature, several ways of formulating query strategies have been proposed, which results in the following general frameworks:
%\begin{itemize}
%    \item Uncertainty Sampling
%    \item Query-By-Committee
%    \item Expected Model Change
%    \item Variance Reduction and Fisher Information Ratio
%    \item Estimated Error Reduction
%    \item Density-Weighted Methods
%\end{itemize}



%The second component of an annotator is our \textbf{oracle}. 
%Since human annotations are too time-consuming and inefficient, our annotator is represented by an oracle, which is a machine learning model.
%The job of the oracle is to distinguish negative samples from our sampler from positive triples from \ac{KG}. 
%Therefore, we have a binary classification model which labels triples 0 or 1, where 0 represents a negative and 1 a positive triple.
%Compared to the normal oracle in an active learning process, in our negative sampling process we know the ground-truth value of our triples, as they are either from the KG or generated by the negative sampler.
%We can use this knowledge to give the oracle not only the task of labeling but also feedback to the negative sampler.
%The feedback should be based on various factors, that take into account different criteria for the current generated, negative sample and evaluate it using a combined rank metric.
%For this, we have the following factors in mind, which are combined into one metric:
%\begin{enumerate}
%    \item ranking with gradients - candidates which most surprise the language model
%    \item PEER - relative frequency of relations that peers of an entity have
%    \item POP - popularity of entity
%    \item FRQ - frequency of same subject and predicate (s,p, \_)
%    \item (PIVO - textual background information)
%    \item (ranking with scores - candidates which look more plausible, almost positive)
%\end{enumerate}
%Based on the feedback of the oracle, our active learner either retrained by replacing head or tail with a different entity, or a new positive sample can be retrieved from the \ac{KG} for new training.

% DESCRIBE PROCESS OF SAMPLING in several steps


%Like in other approaches, we can replace both the head and the tail entity with any other entity of the KG to obtain a negative triple.
%This leads to an abundant amount of negative samples at our disposal, but we are not certain about their quality in sense of informativeness and usefulness.
%For this reason, we want our approach to filter out exactly those negative samples from the large pool that represent the greatest possible benefit for the creation of embedding.

%Our proposed negative sampling method contains two components:
%The negative sampler and an oracle giving feedback to the sampler.
%sampler gets two inputs:
% interesting positive triplets from the \ac{KG} 
% feedback from the oracle for the quality of the negative example generated before.
 

%The oracle in turn just receives generated negative examples from the sampler. 
%The evaluation of the quality of the negative sample depends on two factors:
%At first, it measures the probability of the negative example to be a positive one, 
%which indicates the closeness to the positive triple. 
%Secondly, it measures the uncertainty of the \ac{KGE} in this area of a \ac{KG}. 
%For example, if a \ac{KG} is very incomplete or there is less information about this area, the \ac{KGE} is probably uncertain on how to embed these triples and differentiate between positives and negatives.
%Depending on the overall score for the generated negative example, the oracle gives feedback to the sampler.
%Either the sample was not good and has to be retrained, or a new positive sample can be retrieved from the \ac{KG} for new training.
%As a result, the sampler alternates between re-training and selecting new examples in each iteration.




%p(i) = \frac{p_{sampled}(i) \cdot p_{negative}(i)}{\sum_j{p_{sampled}(j) \cdot p_{negative}(j)}}$



%\begin{multline}
%    p_G(h',r,t'|h,r,t)=\frac{\exp score(h',r,t')}{\sum\exp score(h^*,r,t^*)} \\
%    (h^*,r,t^*)\in Neg(h,r,t)
%\end{multline}