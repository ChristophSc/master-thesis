\chapter{Solution}
\label{ch:solution}

% description and general introduction to solution
Our approach is inspired by active learning which is originally well-motivated in many machine learning approaches where unlabeled data is abundant, but it is difficult, time-consuming or expensive to obtain labeled data \cite{Settles2009ActiveLL}.
By active learning approach we aim for greater accuracy with fewer labeled training instances by choosing the data from which we learn from \cite{Settles2009ActiveLL}.
In our case, we want to ensure high accuracy of our embeddings by providing them hard negative samples.
Active Learning contains two components: 
An active learner and an oracle/human annotator.
The architecture of our approach is depicted in Figure \ref{fig:architecture}.
% Figure
\begin{figure}
    \centering
    \includegraphics{figures/uni-logo.pdf}
    \caption{Architecture of our negative sampling approach including two components: An negative sampler which depicts the active learner and an oracle which annotates the samples as positive or negative ones}
    \label{fig:architecture}
\end{figure}

Our \textbf{Negative Sampler} represents the Active Learner, which has the job to provide negative samples for the annotator.
These interesting and useful negative samples are subsequently used to learn the embedding.
As described in related work chapter, we have three different setting available for active learning:
Since we do not know anything about the distribution of negative samples at the beginning, and we have a large pool of negative samples, it would be very time-consuming to rank each instance.
For this reason, \textit{Pool-Based Active Learning} is the least appropriate for our scenario.
So the decision if we chose \textit{Membership Query Synthesis} or \textit{Stream-Based Selective Sampling} depends on if we already have a negative sample pool or we have to create them de novo.
For the former scenario we can select positive samples from the \ac{KG} and generate a negative sample by replacing the head or tail entity.
With this approach the active learner would learn how to replace entities to create useful and informative negative samples.
The latter setting of \textit{Stream-Based Selective Sampling} would already require an existing large pool of negative samples.
This could be done by replacing head or tail entity randomly by any other entity of the \ac{KG} for a set of chosen positive samples.
Since the setting of \textit{Membership Query Synthesis} seem to be less time-consuming and less-memory intense, this one meets our requirements more and, therefore, is used for our scenario.

Each of the active learning settings evaluate the informativeness of unlabeled
instances, which is in our case the informativeness of negative samples \cite{Settles2009ActiveLL}.
In the literature, several ways of formulating query strategies have been proposed, which results in the following general frameworks:
\begin{itemize}
    \item Uncertainty Sampling
    \item Query-By-Committee
    \item Expected Model Change
    \item Variance Reduction and Fisher Information Ratio
    \item Estimated Error Reduction
    \item Density-Weighted Methods
\end{itemize}
In \textit{Uncertainty Sampling}, an active learner queries the instances where it is most uncertain about on how to label it \cite{Settles2009ActiveLL}.
If we use entropy-based Uncertainty Sampling in a binary classification problem like in our case, it is identical to choose the instance whose posterior probability of being positive is nearest to 0.5 \cite{Settles2009ActiveLL}.
Entropy is defined as:
$$x^{*}_{ENT} = \argmax_{x} - \sum_{i}{\mathds{P}(y_i | x; \theta) log \mathds{P}(y_i|x; \theta)}$$
In our scenario of negative sampling, since we have a binary classification between negative (=0) and positive (=1) triples, $<$ 0.5 represents a negative sample and $\geq$ 0.5 a positive sample.
The result is that we query samples that are close to 0.5, or in other words:
we query hard negative samples which are close to be positive.

The second component of an annotator is our \textbf{oracle}. 
Since human annotations are too time-consuming and inefficient, our annotator is represented by an oracle, which a machine learning model.
The job of the oracle is to distinguish negative samples from our sampler from positive triples from \ac{KG}. 
Therefore, we have a binary classification model which labels triples 0 or 1, where 0 represents a negative and 1 a positive triple.
Compared to the normal oracle in an active learning process, in our negative sampling process we know the ground-truth value of our triples, as they are either from the KG, or generated by the negative sampler.
We can use this knowledge to give the oracle not only the task of labeling, but also feedback to the negative sampler.
The feedback should be based on various factors, that take into account different criteria for the current generated, negative sample and evaluate it using a combined rank metric.
For this, we have the following factors in mind, which are combined into one metric:
\begin{enumerate}
    \item ranking with gradients - candidates which most suprise the language model
    \item PEER - relative frequency of relations that peers of entity have
    \item POP - popularity of entity
    \item FRQ - frequency of same subject and predicate (s,p, \_)
    \item (PIVO - textual background information)
    \item (ranking with scores - candidates which look more plausible, almost positive)
\end{enumerate}
Based on the feedback of the oracle, our active learner either retrained by replacing head or tail with a different entity, or a new positive sample can be retrieved from the \ac{KG} for new training.

% DESCRIBE PROCESS OF SAMPLING in several steps
In summary, our negative sampling process contains the following steps:
\begin{enumerate}
    \item Select randomly a positive sample from the KG
    \item Select another entity of KG by Uncertainty Sampling
    \item Generate negative sample by replacing head or tail entity.
    \item Send negative sample to oracle
    \item Negative sample is labeled by oracle with 0 (= negative) or 1 (= positive)
    \item Feedback is calculated based on combined factors
    \item Feedback is sent to active learner
    \item Based on feedback Active Learner either retrains current sample an continues with step 2 or selects a new positive samples and continues with step 1
\end{enumerate}
This training process steps are repeated again and again, such that our Active Learner iteratively improves the quality of generated, negative samples. 


%Like in other approaches, we can replace both the head and the tail entity with any other entity of the KG to obtain a negative triple.
%This leads an abundant amount of negative samples at our disposal, but we are not certain about their quality in sense of informativeness and usefulness.
%For this reason, we want our approach to filter out exactly those negative samples from the large pool that represent the greatest possible benefit for the creation of embedding.

%Our proposed negative sampling method contains two components:
%The negative sampler and an oracle giving feedback to the sampler.
%sampler gets two inputs:
% interesting positive triplets from the \ac{KG} 
% feedback from the oracle for the quality of the negative example generated before.
 
%Consequently, our sampler represents an Active Learner which iteratively improves the training.
%The oracle in turn just receives generated negative examples from the sampler. 
%The evaluation of the quality of the negative sample depends on two factors:
%At first, it measures the probability of the negative example to be a positive one, 
%which indicates the closeness to the positive triple. 
%Secondly, it measures the uncertainty of the \ac{KGE} in this area of a \ac{KG}. 
%For example, if a \ac{KG} is very incomplete or there is less information about this area, the \ac{KGE} is probably uncertain on how to embed these triples and differentiate between positives and negatives.
%Depending on the overall score for the generated negative example, the oracle gives feedback to the sampler.
%Either the sample was not good and has to be retrained, or a new positive sample can be retrieved from the \ac{KG} for new training.
%As a result, the sampler alternates between re-training and selecting new examples in each iteration.

For the implementation of our prototype for our approach we will use rather small datasets and start with  KINSHIP and UMLS.
Subsequently, we want to compare our achieved accuracy with state of the art approaches.
Therefore, we want to use \ac{MRR} and Hit@10 metrices on datasets WN18,WN18RR, FB15K, FB15K237, YAGO3-10.
Additionally, we will test the impact of our negative sampling approach on different embeddings with the given datasets and compare in which areas our method outperforms the current state of the art approaches.
For this reason, we will use the most common embeddings from the three groups of embedding types:
TransE, TransH for \textit{Translation-Based Models}, DistMult and ComplEx for \textit{Tensor Factorization-Based Models}, and ConvE and ConEx für \textit{Neural Network-Based Models}.



%dieses gibt er dann an das oracle, welche anhand der definierten metriken beurteilt, ob es sich um ein gutes oder schlechtes negatives samples handelt.
%wenn das sample gut genug war, wird es verwendet und es wird für das nächste ositive triplet fortgefahren.
%Andernfalls muss der active learner andere instanzen aussuchen, von denen er entweder weiß, dass dies ein gutes neatives sample ist, oder sich sehr unsicher dabei ist, ob es sich um ein gutes oder schlechtes negatives sample handelt.
