\section{Extrinsic Evaluation}
\label{sec:extrinsicevaluation}
We highlight the relevance of negative statements for:
\begin{itemize}
    \item Entity summarization on Wikidata.
    \item Decision support with hotel data from Booking.com.
    \item Question answering on various structured search engines.
\end{itemize}

\subsection{Entity Summarization}
In this experiment we analyze whether mixed positive-negative statement set can compete with standard positive-only statement sets in the task of entity summarization. In particular, we want to show that the addition of negative statements will \textit{increase the descriptive power} of structured summaries.

% 
We collected 100 Wikidata entities from 3 diverse types: 40 people, 30 organizations (including publishers, financial institutions, academic institutions, cultural centers, businesses, and more), and 30 literary works (including creative work like poems, songs, novels, religious texts, theses, book reviews, and more). On top of the negative statements that we infered, we collected relevant positive statements about those entities.\footnote{We defined a number of common/useful properties to each of  type, e.g., for people, ``position held''is a relevant property for positive statements.} We then computed for each entity \textit{e} a sample of 10 positive-only statements, and a mixed set of 7 positive and 3 \textit{correct}\footnote{We manually checked the correctness of these negative statements.} negative statements, produced by the peer-based method. We relied on peering using Wikipedia embeddings~\cite{wikipedia2vec}. Annotators were then asked to decide which set contains more new or unexpected information about \textit{e}. More particularly, for every entity, we asked workers to assess the sets (flipping the position of our set to avoid biases), leading to a total number of 100 tasks for 100 entities. We collected 3 opinions per task. Overall results show that mixed sets with negative information were preferred for 72\% of the entities, sets with positive-only statements were preferred for 17\% of the entities, and the option ``both or neither'' was chosen for 11\% of the entities. Table~\ref{tab:posneg} shows results per each considered type.  The standard deviation is 0.24, and the percentage of queries with full agreement is 22\%.
Table~\ref{tab:won} shows three diverse examples. The first one is \textit{Daily Mirror}. One particular noteworthy negative statement in this case is that the newspaper is not owned by the ``\textit{News U.K.}'' publisher which owns a number of other \textit{British} newspapers like \textit{The Times, The Sunday Times, and The Sun}. The second entity is \textit{Peter the Great} who died in \textit{Saint Petersburg} and not \textit{Moscow}, and who did not receive the \textit{Order of St Alexander Nevsky} which was first established by his wife, a few months after his death. And the third entity is \textit{Twist and Shout}. Although it is a known song by \textit{The Beatles}, they were \textit{not} its composers, writers, nor original performers.

\begin{table*}
  \caption{Results for the entities \textit{Daily Mirror}, \textit{Peter the Great}, and \textit{Twist and Shout}.}
  \label{tab:won}
    \center
    \begin{centering}
  \scalebox{0.9}{
  \begin{tabular}{c|c}
    \toprule
      \multicolumn{2}{c}{\textbf{Daily Mirror}}\\
          \midrule
    \multicolumn{1}{c}{\textbf{Pos-only}} & \multicolumn{1}{c}{\textbf{Pos-and-neg}}\\
    \midrule 
(owned by; Reach plc) & \bf{\textit{$\neg$(newspaper format; broadsheet)}}\\
(newspaper format; tabloid) & (newspaper format; tabloid)\\
(country; United Kingdom) & \bf{\textit{$\neg$(country; U.S.)}}\\
(language of work or name; English) & (language of work or name; English)\\
(instance of; newspaper) & \bf{\textit{$\neg$(owned by; News U.K.)}}\\
... & ...\\
\midrule
      \multicolumn{2}{c}{\textbf{Peter the Great}}\\
          \midrule
    \multicolumn{1}{c}{\textbf{Pos-only}} & \multicolumn{1}{c}{\textbf{Pos-and-neg}}\\
    \midrule 
(military rank; general officer) & (military rank; general officer)\\
(owner of; Kadriorg Palace) & (owner of; Kadriorg Palace)\\
(award; Order of the Elephant) & \bf{\textit{$\neg$(place of death; Moscow)}}\\
(award; Order of St. Andrew) & (award; Order of St. Andrew)\\
(father; Alexis of Russia) & \bf{\textit{$\neg$(award; Knight of the Order of St. Alexander Nevsky)}}\\
... & ...\\
\midrule
      \multicolumn{2}{c}{\textbf{Twist And Shout}}\\
          \midrule
    \multicolumn{1}{c}{\textbf{Pos-only}} & \multicolumn{1}{c}{\textbf{Pos-and-neg}}\\
    \midrule 
(composer; Phil Medley)& \bf{\textit{$\neg$(composer; Paul McCartney)}}\\
(performer; The Beatles) & (performer; The Beatles)\\
(producer; George Martin) & \bf{\textit{$\neg$(composer; John Lennon)}}\\
(instance of; musical composition) & (instance of; musical composition)\\
(lyrics by; Phil Medley) & \bf{\textit{$\neg$(lyrics by; Paul McCartney)}}\\
... & ...\\
    \bottomrule
  \end{tabular}
  }
  \end{centering}
  \end{table*}
  
\begin{table*}
  \caption{Positive-only vs.\ positive and negative statements.}
  \label{tab:posneg}
  \center
  \begin{centering}
  \scalebox{0.99}{
  \begin{tabular}{l|l|l|l}
    \toprule
        \multicolumn{1}{c}{\textbf{Preferred Choice}} & 
        \multicolumn{1}{c}{\bf{Person} \textbf{(\%)}} & \multicolumn{1}{c}{\bf{Organization} \textbf{(\%)}} & \multicolumn{1}{c}{\bf{Literary work} \textbf{(\%)}}\\
            \midrule
    \multicolumn{1}{l}{Pos-and-neg} & \multicolumn{1}{c}{\textbf{71}} &\multicolumn{1}{c}{\textbf{77}}&\multicolumn{1}{c}{\textbf{66}}\\
    \multicolumn{1}{l}{Pos-only} & \multicolumn{1}{c}{22} &  \multicolumn{1}{c}{10} & \multicolumn{1}{c}{17} \\
    \multicolumn{1}{l}{Both or neither} & \multicolumn{1}{c}{7} & \multicolumn{1}{c}{13} & \multicolumn{1}{c}{17}\\
    \bottomrule
  \end{tabular}
  }
  \end{centering}
\end{table*}


In this experiment, we showed that adding negative statements to a set of positive statements increases its quality, and for that, we chose a split of 7 positive and 3 negative statements for top-10 results. One may wonder whether that is actually the best proportion. This motivates another analysis, \textit{finding out the portion of negative statements to be added to a positive top-k set of statements that maximizes the relevance gain} (i.e., nDCG). We used the annotators' assessment of relevancy of individual positive and negative statements. 
 We then compiled them as sets of top-k results with different k values and different portions of negative statements. The decision of adding a certain negative statement should respect the constraint of not decreasing the relevance gain (i.e., nDCG) of the currently chosen top-k results. We calculated the ideal ratio of positive to negative statements for k results. The ideal portion of negative statements within top-k statements about entity \textit{e} was obtained for k=3, 5, 10, and 20. For a set of top-3 or top-5 statements, 1 negative statement is ideal, for 10 statements, 2 are ideal, and for 20, 5 are ideal.

\subsection{Decision Support}
Negative statements are highly important also in specific domains. In online shopping, characteristics not possessed by a product, such as the \textit{IPhone 7} not having a headphone jack, are a frequent topic highly relevant for decision making. The same applies to the hospitality domain: the absence of features such as free WiFi or gym rooms are important criteria for hotel bookers, although portals like Booking.com currently only show (sometimes overwhelming) positive feature sets.

To illustrate this, based on a comparison of 1.8k hotels in India, as per their listing on Booking.com, using the peer-based method, we inferred useful negative features. For peering, we considered all other hotels in India, and for ranking, we computed peer frequencies (\textit{PEER}). We then used crowdsourcing over the results of 100 hotels. We asked annotators to check two sets of features about a given hotel, one set containing 5 random %\sr{I added ``random'' here - is that correct?? This may be a point of criticism - random positives versus top negatives, the negatives are better, but that may just be the ranking? Perhaps tone down/shorten this first evaluation, the second one on decision making is anyway much more interesting} \ha{Yes, random. But random here, unlike with Wikidata, doesn't necessarily mean useless. Like another label for an entity or the weight of a person. Most of the features are common between hotels. But I see your point.} 
positive-only features, and one set containing a mix of 3 positive and 2 negative features. Their task was to choose which set of features will help them more in deciding whether to stay in this hotel or not. They can choose one of the sets, or both. For every hotel, we request 3 annotators.

Table~\ref{tab:hotelsnumber} shows that sets with negative features were chosen 16 percentage points more than the positive-only sets. The standard deviation of this task is 0.22 and the percentage of queries with full agreement is 28\%. Table~\ref{tab:hotels} shows three hotels with useful negative features. Although the \textit{Hotel Asia The Dawn} lists 64 positive features, negative information such as that it does not offer air conditioning and free Wifi may give important clues for decision making.
\begin{table}
  \caption{Usefulness of hotel features.}
  \centering
  \label{tab:hotelsnumber}
  \begin{tabular}{l|l}
    \toprule
        \multicolumn{1}{c}{\textbf{Preferred Choice}} & 
        \multicolumn{1}{c}{\textbf{(\%)}}\\
            \midrule
    \multicolumn{1}{l}{Pos-and-neg} & \multicolumn{1}{c}{\textbf{54}}\\
    \multicolumn{1}{l}{Pos-only} & \multicolumn{1}{c}{38}\\
    \multicolumn{1}{l}{Either or neither} & \multicolumn{1}{c}{8}\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table*}
\caption{Negative statements for hotels in India.}
\centering
\scalebox{0.9}{\begin{tabular}{lcl}
\toprule
\bf{Hotel} & \bf{Number of positive features} & \bf{Top-3 negative features} \\ \midrule
The Sultan Resort & 106 & $\neg$ Parking; $\neg$ Fan; $\neg$ Newspapers\\
Vista Rooms at Mount Road & 28 & $\neg$ Room service; $\neg$ Food \& Drink; $\neg$ 24-hour front desk\\
Hotel Asia The Dawn & 64 & $\neg$ Air conditioning; $\neg$ Free Wifi; $\neg$ Free private parking\\
\bottomrule
\end{tabular}}
\label{tab:hotels}
\end{table*}

Moreover, we collected 20 pairs of hotels from the same dataset, and showed every pair's Booking.com pages to 3 annotators. We asked them to choose the better hotel for them. Then we showed them negative features about the pair, and asked them whether this new information would change their mind on their initial decision. A screenshot of the task is shown in Figure~\ref{fig:hotel}. 42\% changed their pick after negative features were revealed. The standard deviation on this task is 0.15. The full agreement of the 3 annotators on \textit{changing the hotel after negative features were revealed} is 35\%. The full agreement of annotators \textit{choosing the same hotel at the end of the task} is 30\%. The latter agreement measure disregard whether they have changed their decision or stayed with their initial choice.

\begin{figure*}
 \caption{Extrinsic use-case: decision support on hotel data.}
 \centering
\includegraphics[width=0.85\textwidth]{figures/hotel.png}
\label{fig:hotel}
\end{figure*}

\subsection{Question Answering}
In this experiment, we compared the results to negative questions over a diverse set of sources. We manually compiled 20 questions that involve negation, such as \emph{``Actors without Oscars''}\footnote{Sample textual queries: ``actors with no Oscars'', ``actors with no spouses'', ``film actors who are not film directors'', ``football players with no Ballon d'Or'', ``politicians who are not lawyers''.}. We compared them over four highly diverse sources: Google Web Search (increasingly returning structured answers from the Google knowledge graph~\cite{GKG}), WDAqua~\cite{Diefenbach2017} (an academic state-of-the-art KBQA system), the Wikidata SPARQL endpoint~\footnote{\url{https://query.wikidata.org/}} (direct access to structured data), and our peer-based method. For Google Web Search and WD\-Aqua, we submitted the queries in their textual form, and considered answers from Google if they come as structured knowledge panels. For Wikidata and peer-based inference, we transform the queries into SPARQL queries\footnote{sample SPARQL queries: \url{https://w.wiki/A6r}, \url{https://w.wiki/9yk}, \url{https://w.wiki/9yn}, \url{https://w.wiki/9yp}, \url{https://w.wiki/9yq}}, which we either fully executed over the Wikidata endpoint, or executed the positive part over the Wikidata endpoint, while evaluating the negative part over a dataset produced by our peer-based inference method. Note that all queries were safe, since they were designed to always asks for a class of entities (e.g., entities of occupation actor) that do not satisfy a certain property (e.g., having won the Oscar), which was captured via SPARQL MINUS with a shared variable. For each method, we then self-evaluated the number of results, the correctness and relevance of the (top-5) results. All methods were able to return highly correct statements, yet Google Web Search and WDAqua return no results for 18 and 16 of the queries, respectively.

We continued the assessment over a sample of 5 queries. Wikidata SPARQL returned by far the highest number of results, 250k on average, yet did not perform ranking, thus returned results that are hardly relevant (e.g., a local Latvian actor to the Oscar question). The peer-based inference outperforms it by far in terms of relevance (72\% vs.\ 44\% for Wikidata SPARQL). We point out that although Wikidata SPARQL results appear highly correct, this has no formal foundation, due to the absence of a stance of OWA KBs towards negative knowledge. For example, most actors or people did \textit{not} win Oscars, which makes 99.99\% of the entities returned by Wikidata's SPARQL query correct, even under the OWA.

%\section{Discussion}
%\label{sec:disc}
%\ha{Do we still need this section? Since we dropped the text method and our statistical inference methods are now NOT complementary as much as the second is an refined version of the first}
%\newtext{The two presented approaches, namely \textit{peer-based} and \textit{temporal} statistical inference, are believed to be complementary for the following reasons:
%\begin{enumerate}
%    \item Relevance: While there is a sizeable overlap between the negative statements inferred in both methods, the temporal statistical inference is superior with providing more interesting explanations for the inferred statements, as shown in Table~\ref{tab:explanations}. 
%    \item Coverage: For an entity to be considered in the temporal method, it has to be a member of at least one ordered set of peers, which gives the subject coverage advantage in this case to the peer-based method.
%    \item Correctness: Because of its more concrete way of grouping highly related entities, the correctness of the negative statements in the temporal method were shown to be more correct than the similarity based method, as shown in Table~\ref{tab:simvstempcorrec}.
%\end{enumerate}}
