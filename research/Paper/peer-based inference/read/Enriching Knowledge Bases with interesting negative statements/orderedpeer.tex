\section{Order-oriented Peer-based Inference}
\label{sec:temporal}


In the previous section,  we assume a binary peer relation as the basis of peer group computation. In other words,  for each entity, any other entity is either a peer, or is not. Yet in expressive KBs, relatedness is typically graded and multifaceted, thus reducing this to a binary notion risks losing valuable information. We therefore investigate, in this section, how negative statements can be computed while using ordered peer set.

Orders on peers arise naturally when using real-valued similarity functions, such as Jaccard-similarity, or cosine distance of embedding vectors. An order also naturally arises when one uses temporal or spatial features for peering. Here are some examples:
\begin{enumerate}
    \item \emph{Spatial:} Considering the class \emph{national capital}, the peers closest to \textit{London} are \textit{Brussels} (199 miles), \textit{Paris} (213 miles), \textit{Amsterdam} (223 miles), etc.
    \item \emph{Temporal:} The same holds for temporal orders on attributes, e.g., via his role as president, the entities most related to \textit{Biden} are \textit{Trump} (predecessor), \textit{Obama} (pre-predecessor), \textit{Bush} (pre-pre-predecessor), etc.
\end{enumerate}

\noindent
\textbf{Formalization.\ }
%Let $\textit{sim}(e_1,e_2) \rightarrow \mathcal{R}$ be a real-valued similarity function over a pair of entities $e_1,e_2$. 
Given a target entity $e_0$, a similarity function $\textit{sim}(e_a,e_b) \rightarrow \mathcal{R}$, and a set of candidate peers $E=\{e_1,...,e_n\}$, we can sort $E$ by $\textit{sim}$ to derive an ordered list of sets $L=[S_1, ..., S_n]$, where each $S_i$ is a subset of $E$ that consists of highly related entities to $e_0$.
%and for any two members of $S$, $S_i$ and $S_j$ ($i\leq i < j \leq n$), we have 
%$S_i \cap S_j=\emptyset$.
%; that is,  the list is ordered by decreasing similarity
%of peers by assigning all $e\in E$ into sets ordered by decreasing similarity.}
%\GW{this is a little awkward and could be avoided/simplified; why don't you just say that the order induces a list of entities L = [$e_{i_1}, e_{i_2}$ ...].
%then you can say that because of ties this could be a partial order and could then be grouped into a list of lists S ...; but I doubt that you really need this list of lists S; I tend to think that all of the subsequent materials can also be cast into operating over L (with ties randomly broken)!!!}\ha{**}\\
% SR: Simplified it, but note that we do not want to break ties at random, as the boundaries carry important information (winners of the last 3 years), which are lost if we allow arbitrary sizes (last 2, 3, 4, 5, 6, 7 winners)
\begin{example}
Let us consider temporal recency of having won the \textit{Oscars for Best Actor/Actress} as similarity function w.r.t. the target entity %... (winner of the Physics Nobel Prize in ???). Then, the ordered list of peers would be: \term{[\{Wilhelm Röntgen\}, ..., \{Emilio Segrè, Owen Chamberlain\}, \{Don\-ald Glaser\}, \{Robert Hofstadter, Rudolf Mössbauer\}, \{L\-ev Landau\}, \{Maria Mayer, J. Hans Jensen, Eugene Wign\-er\}..., \{James Peebles, Michel Mayor, Di\-dier Queloz\}].}
\emph{Olivia Colman}.   The ordered list of closest peer sets $S$ is 
\term{[\{Frances McDormand, Gary Oldman\}, \{Emma Stone, Casey Affleck\}, \{Brie Larson, L\-eonardo DiCaprio\}, \{Julianne Moore, Eddie Redmayne\}.., \{Janet Gaynor, Emil Jannings\}].}
\end{example}


Given an index of interest $m$ ($m \leq n)$, we have a prefix list $S_{[1,m]}$   of such an ordered peer set list $L$. For any negative statement candidate $\textit{stmt}$, we can     compute two ranking features:

\begin{enumerate}
    \item \emph{Prefix-volume (VOL)}: The prefix volume denotes the size of the prefix in terms of peer entities considered, i.e., $\textit{VOL}=|S_1 \cup ... \cup S_m|$. Note that the volume should not be mixed with the length $m$ of the prefix, which does not allow easy comparison, as sets may contain very different numbers of members.
    \item \emph{Peer frequency (PEER)}: As in Section~\ref{sec:inference}, \textit{PEER} denotes the fraction of entities in $S_1 \cup ... \cup S_m$ for which \textit{stmt} holds, i.e., $\textit{FRQ}$ / $\textit{VOL}$, where $\textit{FRQ}$ is the number of entities sharing the statement.
\end{enumerate}

Note that these two ranking features change values with prefix length. In addition, we can also consider static features like \textit{POP} and \textit{PIVO}, as introduced before.\\



Consider the entity $e$=\textit{Olivia Colman} from our example, with prefix length 3. For the statement \term{(citizen of; U.S.)}, $\textit{FRQ}$ is 5 and $\textit{VOL}$ is 6, i.e., unlike \emph{Olivia Colman}, 5 out of the 6 winners of the previous 3 years are U.S. citizens. Now considering prefix length 2, for the statement \term{(occupation;  director)}, $\textit{FRQ}$ is 1 and $\textit{VOL}$ is 4, i.e., unlike \emph{Olivia Colman}, 1 out of the 4 winners of the previous 2 years are directors.

We can now proceed to the actual problem of this section.

\medskip

\noindent
\textbf{Research Problem 2.\ }
Given an entity $e$ and an ordered set of peers, compile a ranked list of useful %explanation-augmented 
negative statements.\\

% explanations need to be introduced before we can use them in the definition!!

\noindent
\textbf{Ranking.\ }
What makes a negative statement from an ordered peer set \textit{informative}? It is easy to see that a statement is preferred over another, if it has both a higher peer frequency (\textit{PEER}) and prefix volume (\textit{VOL}). For example, the statement $\neg$\term{(citizen of; U.S.)} above is preferable over $\neg$\term{(occupation; director)}, due to it being both reported on a larger set of peers, and with higher relative frequency.  Yet statements can be incomparable along these two metrics, and this problem even arises when comparing a statement with itself over different prefixes: Is it more helpful if 3 out of the previous 4 winners are \textit{U.S.} citizens, or 7 out of the previous 10?

To resolve such situations, we propose to map the two features into a single one as follows:
\begin{equation}
\label{eqn:context}
score(\textit{stmt},L,m) = \lambda \cdot \textit{PEER} + (1-\lambda) \cdot log(\textit{FRQ})
\end{equation}
%\end{defn}}

where $\lambda$ is again a parameter allowing to trade off the effects of the two variables. Note that we propose a logarithmic contribution of \textit{FRQ} - this is based on the rationale that larger number of peers is preferable. For example, for the same \textit{PEER} value 0.5, we can have a statement with 5 peers out of 10 and 1 peer out of 2.

%\newtext{The first part of the equation, $\frac{k}{l}$, is fraction of the number of entities $k$ that have $s$ in their list of statements and the number of read entities (in other words, the length of the prefix) $l$. The second part, $log(k)$ is added to give ensure higher scores for more frequent statements. For instance, with two statements $s_{1}$ and $s_{2}$, with $s_{1}$ appearing for 1 of the last 2 peers, and $s_{2}$ appearing for 10 of the last 20 peer. They will both receive the same $\frac{k}{l}$ = 0.5. However $s_{2}$ will get a higher overall score because it is more frequent.}
Given the above example, the score for \emph{Olivia Colman}'s negative statement $\neg$\term{(citizen of; U.S.)} at prefix length 3 and $\alpha=0.5$ is $0.76$, with verbalization as ``unlike 5 of the previous 6 winners''. The same statement with prefix length 2 will receive a score of $0.61$, with verbalization as ``unlike 3 of the previous 4 winners''. As for $\neg$\term{(occupation; director)} at prefix length 3 and $\alpha=0.5$ is $0.08$, with verbalization as ``unlike 1 of the previous 6 winners''.  The same statement with prefix length 2 will receive a score of $0.13$, with verbalization as ``unlike 1 of the previous 4 winners''. This example is illustrated in Figure~\ref{fig:diagram}.\\

\noindent
\textbf{Computation.\ }
Having defined how statements over ordered peer sets can be ranked, we now present an efficient algorithm, Algorithm~\ref{alg:contextualizations}, to compute the optimal prefix length per statement candidate, based on a single pass over the prefix. Given the entity $e$=\textit{Olivia Colman}, ordered sets of her peers are collected in line 2.
\begin{equation*}
\begin{split}
L = [\text{winners of Oscar, winners of BAFTA,}\\ \text{..., recipients of CBE}].
\end{split}
\end{equation*}
For readability, we proceed with one ordered peer group, namely the winners of Oscar for Best Actor/Actress. The group contains ordered winners prior to $e$.
\begin{equation*}
\begin{split}
L_\text{winners of Oscar} = [\{\text{Frances McDormand, Gary Oldman}\},\\ \{\text{Emma Stone, Casey Affleck}\},\\ \{\text{Brie Larson, Leonardo DiCaprio}\},\\ \{\text{Julianne Moore, Eddie Redmayne}\}\\ \text{..,}\\ \{\text{Janet Gaynor, Emil Jannings}\}].
\end{split}
\end{equation*}
Similar to the previous algorithm, all statements of the peers are then retrieved from the KB (line 11 and 12). For every candidate statement $st$, the score(s) of the statement is computed with different prefix lengths (loop at line 27), starting with $pos$ (position of $e$ in the ordered set) and stopping at the start position 1. The maximum score is then returned with its corresponding values of \textit{FRQ} and \textit{VOL}, i.e., $max\_\mathit{frq}$ and $max\_\mathit{vol}$ (line 37). The returned candidate statement with its highest score (within one ordered group of peers $L_i$) is compared across many ordered groups of peers (i.e., other groups in $L$), to be either replaced or disregarded from the final list of negations $N$.

%\newtext{Our second statistical inference method introduces two key differences. First, it proposes the term \textit{``contextualization''} of negative statements. We implicitly used contextualizations already in the previous method, for \textit{Einstein not being Communist}, the contextualization was for instance ``40 out of 80 similar entities are Communists''. In the present method, where we group using temporal signals, this gets much more \emph{concrete}. Now a precondition is required so that we can infer useful negations about $e$, namely that $e$ should be a member of at least one \textit{time-based peer group}. For example if $e$ is \term{Barack Obama}, this condition is fulfilled because he is a member of several time-based peer groups: presidents of the United States (44th), member of the State Senate of Illinois (between 1997 and 2004), and United States senator (between 2005 and 2008).}

%\newtext{Second, unlike in the similarity-based method where the peer group size is fixed and where peers are not ordered, in this method, different peers have different importance depending on their position in the time-based peer group. We consider more dynamic peer groups by introducing an additional mode for peering, shown in Algorithm~\ref{alg:contextualizations} and discussed later in more details. 


%The idea behind it is that a negative statement might be more useful in specific time frames, where a portion of the peer group is considered. 

%For example, given the time-based peer group of presidents of the United States, the negation stating that the 22nd president, \textit{Grover Cleveland}, was \textit{not} Republican might not be as useful considering the full group of presidents, as when pointing out that he was the first non-Republican president after 4 consecutive Republican presidents. \ha{To do: I will change examples to fit one theme: scientists and Nobel winners but let's talk big picture first and whether we need to change the way we're presenting this section.}}

%\ha{We need a clearer definition of the time-based group, we can specify what do they have in common (Case 1: a 'category' or a group title which is mainly a PO they share, like award; Nobel in Physics and with this ePO a specific time signal .. could be a from/to or a point in time; Case 2: no specific title but a property indicating time order 'follows' and for this I use the type of the entities as the title of the group; for example 'songs')}
%\newtext{We introduce the \emph{temporal statistical inference} method formally.}

%\textbf{Formalization.\ }
%\newtext{\begin{defn}[Time-based peer group]
%A time-based peer group is an ordered list $[S_1, \ldots, S_n]$ of sets $S_i$ of entities. Given an entity $e$ and a time-based peer group $t$ in which $e$ occurs first in $S_i$, the prefix for $e$ is the list $[S_1, \ldots, S_{i-1}]$. \footnote{For sake of simplicity, in the rare case of later occurrences of an entity that appears multiple times, with a gap, in a time series, this definition considers only the prefix before the first occurrence.}

%\end{defn}}



%\newtext{\begin{defn}[Temporal contextualizations] \mbox{ }\\
%Given negative statement $s$ for an entity $e$, a temporal contextualization is a triple ($t$,$k$,$l$), where $t$ is a time-based peer group which $e$ is a member of, and $k$ and $l$ are integers. A temporal contextualization ($t$,$k$,$l$) for $s$ is satisfied, if it is true that among the $l$ entities before $e$ in $t$, for at least $k$, s is true. Additionally, $l$ must exactly match the sum of the sizes of the last sets in the prefix of $e$.
%\end{defn}}
%\jeff{We might need to think again about the use of definitions; some reviewers tend to think that definitions are necessary only when there are theorems using them; others are a bit relax and also accept algorithms that are using them too} \ha{Same comment by Gerhard}
%\newtext{In our example, for \term{Maria Mayer}, $l$ must be either 1, 3, 4, 6, etc, as there is no order inside sets, so a statement with $l=2$ - ``among the past 3 winners'' is not meaningful, as there is 1 winner in the previous year, and then 3 previous winners considering the past two years, and then 3 winners considering the past three years.}\sr{The previous example is a negative one (i.e., what is not permitted) - better to start with an example of something permitted} \ha{I'm not sure I understand. I'm trying to show what l means and why do we have l to begin with.}
%\newtext{\begin{defn}[\small Maximal temporal contextualization] \mbox{ }
%A contextualization is maximal, if it is not dominated by any other satisfied contextualization. 
%\end{defn}}
%\newtext{\begin{defn}[Scoring contextualizations] \mbox{ }

%\textbf{Ranking time-based negative statements.\ }


%\newtext{\begin{problem}
%Given an entity $e$ that participates in a time-based peer group $t$, compile a ranked list of useful grounded negative statements, with time-based explanations.
%\end{problem}}
%\ha{This is different from problem 1 which is specific to baseline method (then we might want to move problem 1 to Section 4. In problem 2, an entity has to be a member of at least one time-based peer group and we're only considering grounded negative statements for higher correctness.}
%\sr{You are right, either we have a problem statement in either section or in none, I will rethink this.}




\begin{figure}
 \caption{Retrieving useful negative statements about \textit{Olivia Colman}, using an ordered peer group.}
\includegraphics[width=\linewidth]{figures/diagram}
\label{fig:diagram}
\end{figure}


\begin{algorithm*}[t!]
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \Input{\small knowledge base $\mathit{KB}$, entity $e$, ordered peer collection function \textit{ordered\_peers}, \small number of results $k$, \small hypeparameter of scoring function $\alpha$}
    \Output{ \small top-$k$ negative statement candidates for $e$}
        
        \textit{\textbf{L}}$[]$= \textit{ordered\_peers}$(e)$ \Comment{List of ordered peer group(s); Group $L_i$ at position $i$ is one ordered group (list).}\\
         \textit{\textbf{N}}$[]$= $\emptyset$ \Comment{\small Ranked list of negative statements about $e$.}\\
    \For{$L_i$ $\in$ \textbf{L}}{
        $candidates$ = [] \\
        $pos$=position($L_i$, $e$) \Comment{\small Position of $e$ in the ordered set.}\\
        \For{$pe$ $\in$ $L_i$}{ 
            \If{$pe$ == $p$}{continue}
            $candidates$+=$collectP(pe)$\\
            $candidates$+=$collectPO(pe)$
        }
        $ucandidates$ = $unique(candidates)$\\
        \For{$st$ $\in$ $ucandidates$}{
            $sc$ = $scoring(st, L_i, e, pos, \alpha)$ \Comment{\small Dynamic scoring of every statement st with different prefix lengths.}\\
            \If{$getnegation(N, st).score$ $<$ $sc$}{ $setscore(N, st, sc)$}
        }
     }
        $N$-=$\mathit{inKB}(e,N)$\\
        return $max(N,k)$
    \texttt{\\}
    \texttt{\\}
    \SetKwFunction{FMain}{scoring}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$st$, $S$, $e$, $pos$, $\alpha$}}{
        max\_sc = - $\inf$; max\_frq = - $\inf$; max\_vol = - $\inf$; \Comment{Initializing the maximum score, frequency, and volume for statement $st$.}\\
        frq = 0; vol=0; \Comment{Initializing the frequency and volume of statement $st$.}\\
         \For{$j$ = $pos$; $j$ $>=$ 1; $j{-}{-}$}
             {
                vol += countentities($S[j]$) \Comment{\small Computing number of entities at position $j$.}\\
                frq += countif($st$, $candidates$, $S[j]$) \Comment{\small Computing number of entities at position $j$ that share $st$.}\\
                sc = $\alpha * \frac{frq}{vol} + (1-\alpha)* log(frq)$ \Comment{Computing the score of $st$ at position $j$.}\\
                 \If{sc $>$ max\_sc}{
                 max\_sc = sc;\\
                 max\_frq = frq;\\
                 max\_vol = vol\; 
                }
         }}
         \textbf{return} max\_sc, max\_frq, max\_vol\\
\caption{Order-oriented peer-based candidate retrieval algorithm.}
\label{alg:contextualizations}
\end{algorithm*}